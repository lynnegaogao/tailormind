import time
import json
import base64
import io
import re
import os
from flask import Response
from flask import jsonify
from .sft import MinderLLM
from openai import OpenAI

historical=True
# historical=False

OPENAI_API_KEY="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"
minderllm=MinderLLM(model_path='E:\Vis24-TailorMind\sftmodel\llama_factory\sft_v1.0',device='cuda:0')

knowledgeLevel=["Concept","Principle / Math formula","Application","Implementation","Significance / Influence","Related Knowledge","Contrast Knowledge","Extended Knowledge"]
class Custom:
    def chat(self, body):
        # Text messages are stored inside request body using the Deep Chat JSON format:
        # https://deepchat.dev/docs/connect
        print(body)
        # Sends response back to Deep Chat using the Response format:
        # https://deepchat.dev/docs/connect/#Response
        #return {"text": "This is a respone from a Flask server. Thank you for your message!"}
        response = {'text': "This is a response from a Flask server. Thank you for your message!"}
        return response

    def chat_stream(self, body):
        # Text messages are stored inside request body using the Deep Chat JSON format:
        # https://deepchat.dev/docs/connect
        print(body)
        response_chunks = "This is a response from a Flask server. Thank you for your message!".split(
            " ")
        response = Response(self.send_stream(response_chunks), mimetype="text/event-stream")
        response.headers["Content-Type"] = "text/event-stream"
        response.headers["Cache-Control"] = "no-cache"
        response.headers["Connection"] = "keep-alive"
        response.headers["Access-Control-Allow-Origin"] = "*"
        return response

    def send_stream(self, response_chunks, chunk_index=0):
        if chunk_index < len(response_chunks):
            chunk = response_chunks[chunk_index]
            yield f"data: {json.dumps({'text': f'{chunk} '})}\n\n"
            time.sleep(0.07)
            yield from self.send_stream(response_chunks, chunk_index + 1)
        else:
            yield ""

    def save_file_locally(self, file):
        upload_folder = 'uploads'
        if not os.path.exists(upload_folder):
            os.makedirs(upload_folder)  # å¦‚æœç›®å½•ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»ºç›®å½•
        file_path = os.path.join(upload_folder, file.filename)
        file.save(file_path)  # ä¿å­˜æ–‡ä»¶åˆ°æœ¬åœ°ç›®å½•
        return file_path

    def files(self, request):
        # æ–‡ä»¶ä¼ è¾“
        files = request.files.getlist("files")
        file_data = []
        file_paths = []
        
        if files:
            for file in files:
                print("Files:",file.filename)
                file_path = self.save_file_locally(file)  # ä¿å­˜æ–‡ä»¶å¹¶è·å–æ–‡ä»¶è·¯å¾„
                print("Save to file path:",file_path)
                file_paths.append(file_path)

                file.seek(0)

                file_content = base64.b64encode(file.read()).decode('utf-8')
                print(file_content[:100])
                file_data.append({
                    'filename': file.filename,
                    'content': file_content
                })

                # è¯·æ±‚openai apiè·å–file structure + knowledge list
                # ä½¿ç”¨å†å²æ•°æ®
                if historical==True:
                    with open('E:/Vis24-TailorMind/tailormind/back/history/1_material_overview.json', 'r') as file:
                        file_insights=json.load(file)
                    with open('E:/Vis24-TailorMind/tailormind/back/history/2_knowledge_list.json', 'r') as file:
                        knowledgeList=json.load(file)
                    
                # ç”¨æˆ·å®é™…æ•°æ®
                else:
                    file_openai_response=self.get_file_insights(file_path)
                    file_insights=file_openai_response['fileoverview']
                    knowledgeList=file_openai_response['knowledgelist']
                
                fileStructure = file_insights['file_structure']
                fileSummary=file_insights['summary']
                
            # è¯·æ±‚sftè·å–relationsï¼Œè¯·æ±‚openai apiè·å–æ¨èçš„mindmapæ•°æ®
            relations=[]  
            # ä½¿ç”¨å†å²æ•°æ®
            if historical==True:
                with open('E:/Vis24-TailorMind/tailormind/back/history/3_relations.json', 'r') as file:
                        relations=json.load(file)
                with open('E:/Vis24-TailorMind/tailormind/back/history/4-mindmap.json', 'r') as file:
                        mindmap=json.load(file)
            # ç”¨æˆ·å®é™…æ•°æ®
            else:
                for knowledge in knowledgeList:
                    prompt="For a given AI-related knowledge point, generate a triad of knowledge points associated with it. Each triad should be expressed in the form of [Topic,Relationship,Object] as a way to form a complete knowledge representation. Topic is the given knowledge point, object is the extended knowledge point related to the topic, and relation is the logical relationship between topic and object. For example, [[\"Convolutional Networks\", \"Loss Function\", \"Cross Entropy Loss\"],...]. The knowledge point is:"
                    body=prompt+knowledge
                    print("æ­£åœ¨å¤„ç†ï¼š",knowledge)
                    response=minderllm.generate(query=body)
                    print(response['text'])
                    relations.append(eval(response['text']))
                print(str(relations))
                mindmap=self.get_mindmap(str(relations))
                #     relations.append(relation)
                # for relation in eval(response['text']): 
                #     relations.append(relation)
                # with open('E:/Vis24-TailorMind/tailormind/back/history/3_relations.json', 'w') as file:
                #     json.dump(relations, file)
            # print("mindmapæ•°æ®ï¼š",mindmap)
            
            # è¯·æ±‚sftè·å–relations
            questions_rmd=[]
            # ä½¿ç”¨å†å²æ•°æ®
            if historical==True:
                with open('E:/Vis24-TailorMind/tailormind/back/history/5-question_rmd.json', 'r') as file:
                        questions_rmd=json.load(file)
            # ç”¨æˆ·å®é™…æ•°æ®
            else:
                for knowledge in knowledgeList:
                    for level_index in range(0,len(knowledgeLevel)):
                        body="Please recommend 1-2 question(s) about"+knowledge+"from a"+knowledgeLevel[level_index]+"perspective."
                        response=minderllm.generate(query=body)
                        questions = response['text'].split('\n')
                        for question in questions:
                            # åˆ é™¤é—®é¢˜ç¼–å·
                            question_text = re.sub(r"^\d+\.\s*", "", question)
                            question_obj={
                                "question":question_text,
                                "knowledgepoint": knowledge,
                                "level":level_index+1
                            }
                            print(question_obj)
                            questions_rmd.append(question_obj)
            # with open('E:/Vis24-TailorMind/tailormind/back/history/5-question_rmd.json', 'w') as file:
            #     json.dump(questions_rmd, file)   
            
            # è¯·æ±‚openai apiè·å–learning pathæ•°æ®
             # ä½¿ç”¨å†å²æ•°æ®
            if historical==True:
                with open('E:/Vis24-TailorMind/tailormind/back/history/6-learning_path.json', 'r') as file:
                        learningPath=json.load(file)
            # ç”¨æˆ·å®é™…æ•°æ®
            else:
                learningPath=self.get_learningpath(mindmap)
                
            response={
                'chatdata':{"text": "Get files! Loading..."},
                'filestructure':fileStructure,
                'file':file_data,
                'filesummary':fileSummary,
                'mindmap':mindmap,
                'questionrmd':questions_rmd,
                'learningpath':learningPath
            }
            
            return response

        else:
            body = request.json["messages"][0]['text']
            print("Text messages:",body )
            # å¼•å¯¼é—®é¢˜
            if body=='What is Self-Regulated Learning (SRL)?':
                response={"text":"Self-Regulated Learning (SRL) consists of 3 phases:ğŸ“‘ğŸ“‘ğŸ“‘\n 1. **Forethought**, planning and activation \n 2. **Performance**, monitoring and control \n 3. Reaction and **reflection**","html":"<div class=\"deep-chat-temporary-message\"><button class=\"deep-chat-button deep-chat-suggestion-button\" style=\"margin-top: 6px\">What does each view of Tailor-Mind do?</button><br><button class=\"deep-chat-button deep-chat-suggestion-button\" style=\"margin-top: 6px\">How can I start my SRL journey?</button></div>"}
            elif body=='What does each view of Tailor-Mind do?':
                response={"text":"ğŸˆSome guidances will be coming...","html":"<div class=\"deep-chat-temporary-message\"><button class=\"deep-chat-button deep-chat-suggestion-button\" style=\"margin-top: 6px\">How can I start my SRL journey?</button></div>"}
            elif body=='How can I start my SRL journey?':
                response={"text":"ğŸ¥³**Upload your learning material** and start your SRL journey!"}
            # é—®é¢˜æ¨è
            elif body.startswith("Recommend some questions"):
                response=minderllm.generate(query=body)
                # éœ€è¦åˆ é™¤ï¼Œæš‚æ—¶ä½¿ç”¨
                # response={"text":"1. What is Self-Regulated Learning (SRL)?\n2. What does each view of Tailor-Mind do?\n3. How can I start my SRL journey?"}
                html_response=self.convert_rmdText_to_html(response)
                response=html_response
            # è¯¢é—®æ˜¯å¦æ¥å—æ¨èçš„mindmapæ•°æ®
            elif body=='The learning material information has been loaded.':
                response={
                    "text": "ğŸ¤²Will you take the **Mindmap View** recommended by Tailor-Mind and make the next step in the **Learning Path View**?",
                    "html": "<div class=\"deep-chat-temporary-message\"><button class=\"deep-chat-button deep-chat-suggestion-button\" style=\"border: 1px solid green; margin-right: 10px\">Yes</button><button class=\"deep-chat-button deep-chat-suggestion-button\" style=\"border: 1px solid #d80000\">No</button></div>",
                }
            # æ¥å—æ¨èçš„mindmapæ•°æ®+ç”Ÿæˆæ¨èçš„learning path
            elif body=='keep mindmap data':
                
                response={
                    "text": "ğŸ‘»Generating recommended Learning Path...",
                }
            # å°†mindmapä¿®æ”¹ä¸ºé»˜è®¤æ•°æ®ï¼ˆlevel=0å’Œsize=1ï¼‰
            elif body=='change mindmap data to default':
                response={
                    "text": "ğŸˆChanging the Mindmap View to default...",
                }
            # è¯¢é—®æ˜¯å¦è¿›å…¥reflectioné˜¶æ®µ
            elif body=='end':
                response={
                    "text": "ğŸ‘»Will you finish your learning? \nAnd ready to start the **Reflection** phase?ğŸ¤©",
                    "html": "<div class=\"deep-chat-temporary-message\"><button class=\"deep-chat-button deep-chat-suggestion-button\" style=\"border: 1px solid green; margin-right: 10px\">Yes</button><button class=\"deep-chat-button deep-chat-suggestion-button\" style=\"border: 1px solid #d80000\">No</button></div>",
                }
            elif body=='continue learning':
                response={
                    "text": "ğŸ‘»Please follow the learning path to continue your learning...",
                }
            elif body=='start reflection phase':
                response={
                    "text": "ğŸ¥³Let's move on to the self-reflection~",
                }
            elif body=="Let's start the last phase!ğŸˆ":
                response={
                    "text": "ğŸ‘»Will you finish your reviewing? \nAnd ready to do any tests?ğŸ¤©",
                    "html": "<div class=\"deep-chat-temporary-message\"><button class=\"deep-chat-button deep-chat-suggestion-button\" style=\"border: 1px solid green; margin-right: 10px\">Yes</button><button class=\"deep-chat-button deep-chat-suggestion-button\" style=\"border: 1px solid #d80000\">No</button></div>",
                }
            # å…¶ä»–æ­£å¸¸é—®ç­”
            else:
                response=minderllm.generate(query=body)
                # éœ€è¦åˆ é™¤ï¼Œæš‚æ—¶ä½¿ç”¨
                # response={"text":"Some guidances will be coming...","html":"<div class=\"deep-chat-temporary-message\"><button class=\"deep-chat-button deep-chat-suggestion-button\" style=\"margin-top: 6px\">What does each view of Tailor-Mind do?</button><br><button class=\"deep-chat-button deep-chat-suggestion-button\" style=\"margin-top: 6px\">How can I start my SRL journey?</button></div>"}

            print("Response:",response)
            return {'chatdata':response}


    def get_file_insights(self, file_path):
        # prompt-1 file structure + overview
        sample = {
            "summary": "The material begins with an introduction to the basic concepts of convex sets, convex functions, convex optimization problems, and Lagrangian dyadic problems. It then explores different types of convex optimization problems, including linear programming, quadratic programming, QCQP, and SDP, and provides examples of practical applications of these problems to machine learning. References are given at the end of the document.",
            "file_structure": [
                {
                    "key": "1",
                    "title": "Convex Sets",
                    "content": "A convex set is a set in which the points on a line segment between any two points are still in the set. Or, given any two points in a set, the line segment connecting those two points is also completely contained in that set.",
                    "children": [
                        {"key": "1-1", "title": "Definition of Convex Set", "content": "A convex set is a set in which the points on a line segment between any two points remain in that set. Or, given any two points in a set, the line segment connecting those two points is also completely contained in that set."} ,
                        {"key": "1-2", "title": "Examples of Convex Sets", "content": "For example, the unit ball is a convex set because the line segment connecting any two points in the unit ball is also completely contained within the unit ball."} ,
                    ]
                },
                {
                    "key": "2",
                    "title": "Convex Functions",
                    "content": "A convex function is a function in which the line connecting any two points in the domain of definition lies above the image of the function. Or, given any two points in the domain of definition and any point on the line connecting these two points, the function value at this point is not greater than the function value at the corresponding point on the line connecting the two points." ,
                    "children": [
                        {"key": "2-1", "title": "First-order conditions for convexity", "content": "A function f(x) is convex in the domain of definition if and only if for any two points x1 and x2 in the domain of definition, there is f(x1) <= f(x2) + f'(x2)(x1 - x2), where f'(x) denotes the derivative of f(x)."} ,
                        {"key": "2-2", "title": "Second-order conditions for convexity", "content": "A function f(x) is convex in the domain of definition if and only if its second-order derivative f''(x) is always greater than or equal to zero in the domain of definition."} ,
                        {"key": "2-3", "title": "Jensen's Inequality", "content": "For a convex function f and any random variable X and any convex function Ï† of X, Jensen's inequality states that the expectation of Ï† is greater than or equal to the expectation of the parameters of Ï†, i.e., E[Ï†(X)] >= Ï†(E[X])."} ,
                        {"key": "2-4", "title": "Sublevel sets", "content": "Sublevel sets of convex functions are also convex functions. Specifically, given a convex function f and a convex set S in its domain of definition, the restriction of the function to S is still a convex function."} ,
                        {"key": "2-5", "title": "Applications of Convex Functions", "content": "Convex functions have a wide range of applications in machine learning, for example, the loss function in a Support Vector Machine (SVM) is a convex function, which guarantees the existence and uniqueness of the globally optimal solution to the SVM problem."} ,
                    ]
                },
                {
                    "key": "3",
                    "title": "Convex Optimization Problems",
                    "content": "Convex optimization problems are optimization problems in which both the objective function and constraints are convex functions. These problems have good properties and can be solved efficiently using convex optimization theory and algorithms." ,
                    "children": [
                        {"key": "3-1", "title": "Definition of Convex Optimization", "content": "Convex optimization problems are optimization problems in which both the objective function and constraints are convex functions. That is, the objective function is convex and the constraints are convex."} ,
                        {"key": "3-2", "title": "Global Optimization of Convex Problems", "content": "An important property of convex optimization problems is that the globally optimal solution exists and is unique. This gives the convex optimization problem a good solution property."} ,
                        {"key": "3-3", "title": "Examples of Convex Optimization Problems", "content": "Many common optimization problems in machine learning, such as quadratic programming problems for support vector machines and maximum likelihood estimation problems for logistic regression, can be reduced to convex optimization problems."} ,
                    ]
                }
            ]
        }
        sample_str = "```json\n" + json.dumps(sample) + "\n```"
        requirements = [
            "Describe the summary and structure of the entire document with following requirements:",
            "1.'summary' is a summary of the document",
            "2.'file_structure' is a tree that describes the structure of the file, depth = 2, and each node represents a chapter or section",
            "3.'key' is the index of the node, only numbers and '-' are allowed",
            "4.'title' is the title of the node",
            "5.'content' is a description of the node in 2-3 sentences.",
            "Only return JSON code without any other content",
            "The JSON format refers to the example below:",
            sample_str
        ]
        user_input = "\n".join(requirements)
        # prompt-2 knowledge list
        sample_list=['Convex Sets',"Jensen's Inequality",'Convex Optimization','Linear Programming','Quadratic Programming','QCQP','SDP','Lagrangian dyadic problems']
        user_input_list='Give all the AI or deep learning related knowledge points contained in the file to avoid duplication.Only return Json code without any other content. The Json format refers to the example below:```json\n'+ json.dumps(sample_list) + '\n```'

        # æ­£åˆ™è¡¨è¾¾å¼è·å–```json```å†…çš„å†…å®¹
        def extract_json_from_string(input_string):
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…JSONéƒ¨åˆ†
            json_pattern = r'```json\n(.*?)```'
            match = re.search(json_pattern, input_string, re.DOTALL)

            if match:
                json_str = match.group(1).strip()
                # è½¬æ¢ä¸ºJSONå¯¹è±¡
                json_data = json.loads(json_str)
                return json_data
            else:
                return None

        # å°è£…å¯¹è¯é€»è¾‘çš„å‡½æ•°
        def get_assistant_response(user_input, thread_id, assistant_id, file_id):
            # åˆ›å»ºæ¶ˆæ¯
            message = client.beta.threads.messages.create(
                thread_id=thread_id,
                role="user",
                content=user_input,
                file_ids=[file_id]
            )

            # 4. run thread
            # Thread é»˜è®¤ä¸ä¼šè¿è¡Œï¼Œéœ€è¦åˆ›å»ºä¸€ä¸ª Run ä»»åŠ¡æ¥æ‰§è¡Œ Threadã€‚
            run = client.beta.threads.runs.create(
                thread_id=thread_id,
                assistant_id=assistant_id,
            )

            # ç­‰å¾…è¿è¡Œä»»åŠ¡å®Œæˆ
            # Thread æ˜¯å¼‚æ­¥æ‰§è¡Œçš„ï¼Œéœ€è¦è½®è¯¢æ£€æŸ¥æ˜¯å¦æ‰§è¡Œå®Œæˆã€‚
            # Thread æ‰§è¡Œæ—¶ä¼šä¸Šé”ï¼Œåœ¨æ‰§è¡Œå®Œæˆå‰ä¸å¯ä»¥å†æ·»åŠ  message æˆ–è€…æäº¤æ–°çš„ Run ä»»åŠ¡ã€‚
            while True:
                run = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run.id)
                if run.status not in ["queued", "in_progress"]:
                    break
                time.sleep(1)

            # è·å– AI è¾“å‡ºç»“æœ
            messages = client.beta.threads.messages.list(thread_id=thread_id)

            # ä»æ¶ˆæ¯ä¸­å–å‡º AI è¾“å‡ºçš„ JSON å­—ç¬¦ä¸²
            ai_output = messages.data[0].content[0].text.value

            return ai_output

         # è¯»å–æ–‡ä»¶å¹¶ä¸Šä¼ åˆ°OpenAI

        with open(file_path, "rb") as file:  # ä½¿ç”¨withè¯­å¥ç¡®ä¿æ–‡ä»¶æ­£ç¡®å…³é—­
            print("Open file.")
            content = file.read()
        
        client = OpenAI(api_key=OPENAI_API_KEY)
        filename = file_path.split("\\")[-1]
        print("File name:",filename)
        content_type = 'application/pdf'  # æ ¹æ®æ–‡ä»¶å®é™…ç±»å‹è®¾ç½®
        file_response = client.files.create(
            file=(filename, content, content_type),
            purpose='assistants'
        )
        # ä»å“åº”ä¸­è·å–æ–‡ä»¶ID
        print("file_response:",file_response)
        # print(dir(file_response))
        file_id = file_response.id  # ä½¿ç”¨å­—å…¸è®¿é—®æ–¹å¼è·å–æ–‡ä»¶ID
        
        # 1. Create an assistant using the file ID
        assistant = client.beta.assistants.create(
            name="File Analysis Assistant",
            instructions="You are a personal file analyzer. When giving you a file and some questions, retrieve and analyze the content of this file as you can and answer the questions as required. If you cannot parse the required Json output, you can give an empty structure that contains only keys.",
            tools=[{"type": "retrieval"}],
            model="gpt-4-0125-preview",
            file_ids=[file_id]
        )

        # 2. create Thread
        thread = client.beta.threads.create() # ï¼ˆå¯é€‰ï¼‰åœ¨åˆ›å»ºæ—¶æŒ‡å®šå¯¹è¯å†…å®¹

        # è·å–file-overview
        file_overview = get_assistant_response(user_input, thread.id, assistant.id, file_id)
        print(file_overview)
        file_overview_json = extract_json_from_string(file_overview)
        
        # è·å–knowledge list
        knowledge_list=get_assistant_response(user_input_list, thread.id, assistant.id, file_id)
        print(knowledge_list)
        knowledge_list_json=extract_json_from_string(knowledge_list)
        
        # 5. delete assistant
        # client.beta.assistants.delete(assistant.id)

        return {'fileoverview':file_overview_json,'knowledgelist':knowledge_list_json}

    def get_mindmap(self,content):
        sample={
        "nodes": [
        {
            "id": "Finite Horizon Markov Decision Process (MDP)",
            "label": "Finite Horizon Markov Decision Process (MDP)",
            "level": 2,
            "size": 5,
        },
        {
            "id": "Linear Quadratic Regulator (LQR)",
            "label": "Linear Quadratic Regulator (LQR)",
            "level": 6,
            "size": 3,
        },
        {
            "id": "Differential Dynamic Programming (DDP)",
            "label": "Differential Dynamic Programming (DDP)",
            "level": 4,
            "size": 2,
        }
    ],
        "links": [
        {
            "source": "Optimal Control Theory",
            "target": "Finite Horizon Markov Decision Process (MDP)",
            "relation": "includes"
        },
        {
            "source": "Finite Horizon Markov Decision Process (MDP)",
            "target": "Markov Chain",
            "relation": "extends"
        },
        {
            "source": "Linear Quadratic Regulator (LQR)",
            "target": "State Space Model",
            "relation": "uses"
        }
    ]
    }
        sample_str = "```json\n" + json.dumps(sample) + "\n```"
        prompt="Parsing the content of this paragraph, each ternary represents [subject, relationship, object], the following data conversion: 1.subject and object are both elements in nodes, \"id\" and \"label\" are the same. 2.\"level\" is an integer between [1,8], 1-8 corresponds to the relationship of learning level as {1: \"Concept\",2: \"Principle / Math formula\",3: \"Application\",4: \"Implementation\",5: \" Significance / Influence\",6: \"Related Knowledge\",7: \"Contrast Knowledge\",8: \"Extended Knowledge\"}, please make a recommendation to a beginner based on the level of knowledge a beginner need to master this knowledge; 3. \"size\" is an integer between [1,5], which indicates the importance of this knowledge, 1 means common, 5 means important, need to be differentiated, please make a recommendation to a beginner; 4. each ternary as links in the elements, \"source\" for the subject, \"target\" is the object, \"relationship\" is the relationship. Only return json data, the format is as follows:"
        user_input=content+prompt+sample_str
        
        OPENAI_API_KEY="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"
        client = OpenAI(api_key=OPENAI_API_KEY)
        assistant = client.beta.assistants.create(
            name="Education Specialist",
            instructions="You are an educational expert who specializes in tutoring beginners in self-study, deleting processed data while giving beginners advice on how to learn. If you cannot parse the required Json output, you can give an empty structure that contains only keys.",
            tools=[{"type": "code_interpreter"}],
            model="gpt-4-0125-preview"
        )

        thread = client.beta.threads.create()

 # åˆ›å»ºæ¶ˆæ¯
        message = client.beta.threads.messages.create(
                thread_id=thread.id,
                role="user",
                content=user_input
            )

            # 4. run thread
            # Thread é»˜è®¤ä¸ä¼šè¿è¡Œï¼Œéœ€è¦åˆ›å»ºä¸€ä¸ª Run ä»»åŠ¡æ¥æ‰§è¡Œ Threadã€‚
        run = client.beta.threads.runs.create(
                thread_id=thread.id,
                assistant_id=assistant.id,
            )

            # ç­‰å¾…è¿è¡Œä»»åŠ¡å®Œæˆ
            # Thread æ˜¯å¼‚æ­¥æ‰§è¡Œçš„ï¼Œéœ€è¦è½®è¯¢æ£€æŸ¥æ˜¯å¦æ‰§è¡Œå®Œæˆã€‚
            # Thread æ‰§è¡Œæ—¶ä¼šä¸Šé”ï¼Œåœ¨æ‰§è¡Œå®Œæˆå‰ä¸å¯ä»¥å†æ·»åŠ  message æˆ–è€…æäº¤æ–°çš„ Run ä»»åŠ¡ã€‚
        while True:
            run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)
            if run.status not in ["queued", "in_progress"]:
                break
        time.sleep(1)

            # è·å– AI è¾“å‡ºç»“æœ
        messages = client.beta.threads.messages.list(thread_id=thread.id)
            # ä»æ¶ˆæ¯ä¸­å–å‡º AI è¾“å‡ºçš„ JSON å­—ç¬¦ä¸²
        ai_output = messages.data[0].content[0].text.value
        
        # æ­£åˆ™è¡¨è¾¾å¼è·å–```json```å†…çš„å†…å®¹
        def extract_json_from_string(input_string):
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…JSONéƒ¨åˆ†
            json_pattern = r'```json\n(.*?)```'
            match = re.search(json_pattern, input_string, re.DOTALL)

            if match:
                json_str = match.group(1).strip()
                # è½¬æ¢ä¸ºJSONå¯¹è±¡
                json_data = json.loads(json_str)
                return json_data
            else:
                return None
            
        ai_output_json=extract_json_from_string(ai_output)
        
        return ai_output_json
    
    def get_learningpath(self,content):
        sample=[{
          "start": 0.00,
          "level": 1,
          "milestone": "Ensemble Learning",
          "importance": 4,
          "subknowledge": [
              {
                  "level": 2,
                  "knowledge": "Concept of Ensemble Learning",
                  "importance": 5,
                  "content": "Ensemble Learning is a machine learning technique that combines several base models in order to produce one optimal predictive model."
              },
              {
                  "level": 2,
                  "knowledge": "Benefits of Ensemble Learning",
                  "importance": 2,
                  "content": "Enhances prediction accuracy and reduces the likelihood of model overfitting by leveraging the strengths of multiple models."
              },
          ]
      },   
      {
          "start": 0.6,
          "level": 5,
          "milestone": "Stacking",
          "importance": 2,
          "subknowledge": [
              {
                  "level": 6,
                  "knowledge": "Introduction to Stacking",
                  "importance": 3,
                  "content": "Stacking involves training a new model to combine the predictions of several base models for improved prediction accuracy."
              },
              {
                  "level": 6,
                  "knowledge": "How Stacking Works",
                  "importance": 3,
                  "content": "It works by using a meta-learner or blender that learns how to best combine the predictions of multiple base models."
              },
              {
                  "level": 6,
                  "knowledge": "Implementing Stacking Models",
                  "importance": 3,
                  "content": "Implementation involves selecting base models, training them on the data, and then training a meta-model to aggregate their predictions."
              },
              {
                  "level": 6,
                  "knowledge": "Use Cases and Examples of Stacking",
                  "importance": 3,
                  "content": "Stacking is widely used in various domains like finance, healthcare, and image recognition for enhancing predictive performance."
              }
          ]
      }]
        sample_str = "```json\n" + json.dumps(sample) + "\n```"
        prompt = """
        Drawing from the structured knowledge map provided, we propose a self-learning pathway tailored for beginners, comprising approximately 8-10 pivotal milestones. 
        The pathway initiates at a starting point labeled "start" ranging from 0 to 1. 
        Each learning objective is categorized under "level" with a scale from 1 to 8, where each level represents a progressive learning stage as follows:
        {1: "Concept", 2: "Principle / Math formula", 3: "Principle / Math formula", 4: "Implementation", 5: "Significance / Influence", 6: "Related Knowledge", 7: "Contrast Knowledge", 8: "Extended Knowledge"}. 
        This categorization aids in crafting a bespoke recommendation for beginners, aligning with the essential knowledge levels they must achieve.
        Furthermore, "milestone" signifies critical knowledge points within the entire knowledge map, serving as significant markers in the learning journey. 
        The "importance" of each milestone is rated on a scale from 1 to 5, with higher values indicating greater significance. 
        Additionally, "subknowledge" outlines essential subtopics under each milestone, where "knowledge" refers to the specific knowledge point, and "content" provides a concise explanation of this point.
        Please ensure the returned data is in JSON format, with the array length exceeding 8 entries, structured as outlined:
        """

        user_input=json.dumps(content)+prompt+sample_str
        
        OPENAI_API_KEY="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"
        client = OpenAI(api_key=OPENAI_API_KEY)
        assistant = client.beta.assistants.create(
            name="Education Specialist",
            instructions="You are an educational expert who specializes in tutoring beginners in self-study, deleting processed data while giving beginners advice on how to learn. If you cannot parse the required Json output, you can give an empty structure that contains only keys.",
            tools=[{"type": "code_interpreter"}],
            model="gpt-4-0125-preview"
        )

        thread = client.beta.threads.create()

 # åˆ›å»ºæ¶ˆæ¯
        message = client.beta.threads.messages.create(
                thread_id=thread.id,
                role="user",
                content=user_input
            )

            # 4. run thread
            # Thread é»˜è®¤ä¸ä¼šè¿è¡Œï¼Œéœ€è¦åˆ›å»ºä¸€ä¸ª Run ä»»åŠ¡æ¥æ‰§è¡Œ Threadã€‚
        run = client.beta.threads.runs.create(
                thread_id=thread.id,
                assistant_id=assistant.id,
            )

            # ç­‰å¾…è¿è¡Œä»»åŠ¡å®Œæˆ
            # Thread æ˜¯å¼‚æ­¥æ‰§è¡Œçš„ï¼Œéœ€è¦è½®è¯¢æ£€æŸ¥æ˜¯å¦æ‰§è¡Œå®Œæˆã€‚
            # Thread æ‰§è¡Œæ—¶ä¼šä¸Šé”ï¼Œåœ¨æ‰§è¡Œå®Œæˆå‰ä¸å¯ä»¥å†æ·»åŠ  message æˆ–è€…æäº¤æ–°çš„ Run ä»»åŠ¡ã€‚
        while True:
            run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)
            if run.status not in ["queued", "in_progress"]:
                break
        time.sleep(1)

            # è·å– AI è¾“å‡ºç»“æœ
        messages = client.beta.threads.messages.list(thread_id=thread.id)
            # ä»æ¶ˆæ¯ä¸­å–å‡º AI è¾“å‡ºçš„ JSON å­—ç¬¦ä¸²
        ai_output = messages.data[0].content[0].text.value
        
        # æ­£åˆ™è¡¨è¾¾å¼è·å–```json```å†…çš„å†…å®¹
        def extract_json_from_string(input_string):
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…JSONéƒ¨åˆ†
            json_pattern = r'```json\n(.*?)```'
            match = re.search(json_pattern, input_string, re.DOTALL)

            if match:
                json_str = match.group(1).strip()
                # è½¬æ¢ä¸ºJSONå¯¹è±¡
                json_data = json.loads(json_str)
                return json_data
            else:
                return None
            
        ai_output_json=extract_json_from_string(ai_output)
        
        return ai_output_json
    
    def convert_rmdText_to_html(self, response):
        questions = response['text'].split('\n')
        html_str = '<div class="deep-chat-temporary-message">'
        # éå†æ‰€æœ‰é—®é¢˜ï¼Œå°†æ¯ä¸ªé—®é¢˜æ·»åŠ åˆ°HTMLå­—ç¬¦ä¸²ä¸­
        for question in questions:
            # åˆ é™¤é—®é¢˜ç¼–å·
            question_text = re.sub(r"^\d+\.\s*", "", question)
            button_html = f'<button class="deep-chat-button deep-chat-suggestion-button" style="text-align: left; margin-top: 6px;">{question_text}</button><br>'
            html_str += button_html
        html_str += '</div>'

        return {'html': html_str}