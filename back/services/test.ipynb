{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json,re,time\n",
    "\n",
    "OPENAI_API_KEY=\"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\"\n",
    "def get_file_structure_in_english(self, file_path):\n",
    "\n",
    "        client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "        # 示例数据\n",
    "        sample = {\n",
    "            \"summary\": \"The material begins with an introduction to the basic concepts of convex sets, convex functions, convex optimization problems, and Lagrangian dyadic problems. It then explores different types of convex optimization problems, including linear programming, quadratic programming, QCQP, and SDP, and provides examples of practical applications of these problems to machine learning. References are given at the end of the document.\",\n",
    "            \"file_structure\": [\n",
    "                {\n",
    "                    \"key\": \"1\",\n",
    "                    \"title\": \"Convex Sets\",\n",
    "                    \"content\": \"A convex set is a set in which the points on a line segment between any two points are still in the set. Or, given any two points in a set, the line segment connecting those two points is also completely contained in that set.\",\n",
    "                    \"children\": [\n",
    "                        {\"key\": \"1-1\", \"title\": \"Definition of Convex Set\", \"content\": \"A convex set is a set in which the points on a line segment between any two points remain in that set. Or, given any two points in a set, the line segment connecting those two points is also completely contained in that set.\"} ,\n",
    "                        {\"key\": \"1-2\", \"title\": \"Examples of Convex Sets\", \"content\": \"For example, the unit ball is a convex set because the line segment connecting any two points in the unit ball is also completely contained within the unit ball.\"} ,\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"key\": \"2\",\n",
    "                    \"title\": \"Convex Functions\",\n",
    "                    \"content\": \"A convex function is a function in which the line connecting any two points in the domain of definition lies above the image of the function. Or, given any two points in the domain of definition and any point on the line connecting these two points, the function value at this point is not greater than the function value at the corresponding point on the line connecting the two points.\" ,\n",
    "                    \"children\": [\n",
    "                        {\"key\": \"2-1\", \"title\": \"First-order conditions for convexity\", \"content\": \"A function f(x) is convex in the domain of definition if and only if for any two points x1 and x2 in the domain of definition, there is f(x1) <= f(x2) + f'(x2)(x1 - x2), where f'(x) denotes the derivative of f(x).\"} ,\n",
    "                        {\"key\": \"2-2\", \"title\": \"Second-order conditions for convexity\", \"content\": \"A function f(x) is convex in the domain of definition if and only if its second-order derivative f''(x) is always greater than or equal to zero in the domain of definition.\"} ,\n",
    "                        {\"key\": \"2-3\", \"title\": \"Jensen's Inequality\", \"content\": \"For a convex function f and any random variable X and any convex function φ of X, Jensen's inequality states that the expectation of φ is greater than or equal to the expectation of the parameters of φ, i.e., E[φ(X)] >= φ(E[X]).\"} ,\n",
    "                        {\"key\": \"2-4\", \"title\": \"Sublevel sets\", \"content\": \"Sublevel sets of convex functions are also convex functions. Specifically, given a convex function f and a convex set S in its domain of definition, the restriction of the function to S is still a convex function.\"} ,\n",
    "                        {\"key\": \"2-5\", \"title\": \"Applications of Convex Functions\", \"content\": \"Convex functions have a wide range of applications in machine learning, for example, the loss function in a Support Vector Machine (SVM) is a convex function, which guarantees the existence and uniqueness of the globally optimal solution to the SVM problem.\"} ,\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"key\": \"3\",\n",
    "                    \"title\": \"Convex Optimization Problems\",\n",
    "                    \"content\": \"Convex optimization problems are optimization problems in which both the objective function and constraints are convex functions. These problems have good properties and can be solved efficiently using convex optimization theory and algorithms.\" ,\n",
    "                    \"children\": [\n",
    "                        {\"key\": \"3-1\", \"title\": \"Definition of Convex Optimization\", \"content\": \"Convex optimization problems are optimization problems in which both the objective function and constraints are convex functions. That is, the objective function is convex and the constraints are convex.\"} ,\n",
    "                        {\"key\": \"3-2\", \"title\": \"Global Optimization of Convex Problems\", \"content\": \"An important property of convex optimization problems is that the globally optimal solution exists and is unique. This gives the convex optimization problem a good solution property.\"} ,\n",
    "                        {\"key\": \"3-3\", \"title\": \"Examples of Convex Optimization Problems\", \"content\": \"Many common optimization problems in machine learning, such as quadratic programming problems for support vector machines and maximum likelihood estimation problems for logistic regression, can be reduced to convex optimization problems.\"} ,\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        sample_str = \"```json\\n\" + json.dumps(sample) + \"\\n```\"\n",
    "        # prmopts\n",
    "        requirements = [\n",
    "            \"Describe the summary and structure of the entire document with following requirements:\",\n",
    "            \"1.'summary' is a summary of the document\",\n",
    "            \"2.'file_structure' is a tree that describes the structure of the file, depth = 2, and each node represents a chapter or section\",\n",
    "            \"3.'key' is the index of the node, only numbers and '-' are allowed\",\n",
    "            \"4.'title' is the title of the node\",\n",
    "            \"5.'content' is a description of the node in 2-3 sentences.\",\n",
    "            \"Only return JSON code without any other content\",\n",
    "            \"The JSON format refers to the example below:\",\n",
    "            sample_str\n",
    "        ]\n",
    "        user_input = \"\\n\".join(requirements)\n",
    "\n",
    "        # 正则表达式获取```json```内的内容\n",
    "        def extract_json_from_string(input_string):\n",
    "            # 使用正则表达式匹配JSON部分\n",
    "            json_pattern = r'```json\\n(.*?)```'\n",
    "            match = re.search(json_pattern, input_string, re.DOTALL)\n",
    "\n",
    "            if match:\n",
    "                json_str = match.group(1).strip()\n",
    "                # 转换为JSON对象\n",
    "                json_data = json.loads(json_str)\n",
    "                return json_data\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "        # 封装对话逻辑的函数\n",
    "        def get_assistant_response(user_input, thread_id, assistant_id, file_id):\n",
    "            # 创建消息\n",
    "            message = client.beta.threads.messages.create(\n",
    "                thread_id=thread_id,\n",
    "                role=\"user\",\n",
    "                content=user_input,\n",
    "                file_ids=[file_id]\n",
    "            )\n",
    "\n",
    "            # 4. run thread\n",
    "            # Thread 默认不会运行，需要创建一个 Run 任务来执行 Thread。\n",
    "            run = client.beta.threads.runs.create(\n",
    "                thread_id=thread_id,\n",
    "                assistant_id=assistant_id,\n",
    "            )\n",
    "\n",
    "            # 等待运行任务完成\n",
    "            # Thread 是异步执行的，需要轮询检查是否执行完成。\n",
    "            # Thread 执行时会上锁，在执行完成前不可以再添加 message 或者提交新的 Run 任务。\n",
    "            while True:\n",
    "                run = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run.id)\n",
    "                if run.status not in [\"queued\", \"in_progress\"]:\n",
    "                    break\n",
    "                time.sleep(1)\n",
    "\n",
    "            # 获取 AI 输出结果\n",
    "            messages = client.beta.threads.messages.list(thread_id=thread_id)\n",
    "\n",
    "            # 从消息中取出 AI 输出的 JSON 字符串\n",
    "            ai_output = messages.data[0].content[0].text.value\n",
    "\n",
    "            return ai_output\n",
    "\n",
    "         # 读取文件并上传到OpenAI\n",
    "\n",
    "        with open(file_path, \"rb\") as file:  # 使用with语句确保文件正确关闭\n",
    "            print(\"Open file.\")\n",
    "            content = file.read()\n",
    "\n",
    "        filename = file_path.split(\"\\\\\")[-1]\n",
    "        print(\"File name:\",filename)\n",
    "        content_type = 'application/pdf'  # 根据文件实际类型设置\n",
    "        file_response = client.files.create(\n",
    "            file=(filename, content, content_type),\n",
    "            purpose='assistants'\n",
    "        )\n",
    "        # 从响应中获取文件ID\n",
    "        print(\"file_response:\",file_response)\n",
    "        # print(dir(file_response))\n",
    "        file_id = file_response.id  # 使用字典访问方式获取文件ID\n",
    "        print(file_id)\n",
    "        # 1. Create an assistant using the file ID\n",
    "        assistant = client.beta.assistants.create(\n",
    "            name=\"File Analysis Assistant\",\n",
    "            instructions=\"You are a customer support chatbot. Use your knowledge base to best respond to customer queries.\",\n",
    "            tools=[{\"type\": \"retrieval\"}],\n",
    "            model=\"gpt-4-1106-preview\",\n",
    "            file_ids=[file_id]\n",
    "        )\n",
    "\n",
    "        # 2. create Thread\n",
    "        thread = client.beta.threads.create() # （可选）在创建时指定对话内容\n",
    "\n",
    "        ai_output = get_assistant_response(user_input, thread.id, assistant.id, file_id)\n",
    "        print(ai_output)\n",
    "        ai_output_json = extract_json_from_string(ai_output)\n",
    "\n",
    "        # 5. delete assistant\n",
    "        client.beta.assistants.delete(assistant.id)\n",
    "\n",
    "        return ai_output_json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ThreadMessage(id='msg_q1DAl07hMzd0S5EAJvMBeQ47', assistant_id='asst_OMpUdcC6rtRANjpMoPngQUpX', content=[MessageContentText(text=Text(annotations=[], value='```json\\n{\\n  \"summary\": \"This document is an advanced introduction to deep learning in machine learning, covering the concept, motivation, history, and structure of deep architectures. It explains the purpose of these architectures, their neurobiological motivation, their development history, and breakthrough achievements. Notable contributions like convolutional networks, Deep Belief Networks, and autoencoders are discussed. The document highlights theoretical advantages, and explains the structures of convolutional networks using LeNet 5 and ImageNet Classification as case studies.\",\\n  \"file_structure\": [\\n    {\\n      \"key\": \"1\",\\n      \"title\": \"Definition and Motivation\",\\n      \"content\": \"The document defines deep architectures as composed of multiple levels of non-linear operations, such as neural networks with many hidden layers. The goal is to create hierarchies of features where higher levels are formed by the features of lower levels. The introduction includes visual examples.\",\\n      \"children\": []\\n    },\\n    {\\n      \"key\": \"2\",\\n      \"title\": \"History of Deep architectures\",\\n      \"content\": \"Discusses the timeline of deep learning research, from early challenges in training multi-layer networks to breakthroughs like convolutional neural networks in 1998 and major advancements in 2006 with the development of Deep Belief Networks and autoencoders.\",\\n      \"children\": []\\n    },\\n    {\\n      \"key\": \"3\",\\n      \"title\": \"Theoretical Advantages of Deep Architectures\",\\n      \"content\": \"Explains the representation efficiency of deep architectures over shallow ones, conveying the computational and statistical benefits of depth in neural networks for representing complex functions.\",\\n      \"children\": []\\n    },\\n    {\\n      \"key\": \"4\",\\n      \"title\": \"Convolutional Networks\",\\n      \"content\": \"Detailed explanation of convolutional networks, their structure and inspiration from the visual system\\'s structure. It discusses LeNet 5 as a classic example with explanations of each layer and ImageNet Classification using deep convolutional networks.\",\\n      \"children\": [\\n        {\\n          \"key\": \"4-1\",\\n          \"title\": \"Deep Convolutional Networks Introduction\",\\n          \"content\": \"This section introduces deep convolutional networks, emphasizing their complex structures and challenges of training, with the exception of convolutional neural networks (CNNs).\"\\n        },\\n        {\\n          \"key\": \"4-2\",\\n          \"title\": \"LeNet 5 Case Study\",\\n          \"content\": \"Describes the architecture and operation of LeNet 5, providing details on its layers, their functions, and input handling.\"\\n        },\\n        {\\n          \"key\": \"4-3\",\\n          \"title\": \"ImageNet Classification with Deep Convolutional Neural Networks\",\\n          \"content\": \"Outlines ImageNet\\'s large dataset, the challenge it poses for visual recognition, and the results achieved using deep convolutional networks.\"\\n        }\\n      ]\\n    }\\n  ]\\n}\\n```'), type='text')], created_at=1709450505, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_RAXodHmP2LT8Zka4wADfjjJ8', thread_id='thread_U0TWIw1J6svNK7ZJWTHc0kqg')\n",
      "```json\n",
      "{\n",
      "  \"summary\": \"This document is an advanced introduction to deep learning in machine learning, covering the concept, motivation, history, and structure of deep architectures. It explains the purpose of these architectures, their neurobiological motivation, their development history, and breakthrough achievements. Notable contributions like convolutional networks, Deep Belief Networks, and autoencoders are discussed. The document highlights theoretical advantages, and explains the structures of convolutional networks using LeNet 5 and ImageNet Classification as case studies.\",\n",
      "  \"file_structure\": [\n",
      "    {\n",
      "      \"key\": \"1\",\n",
      "      \"title\": \"Definition and Motivation\",\n",
      "      \"content\": \"The document defines deep architectures as composed of multiple levels of non-linear operations, such as neural networks with many hidden layers. The goal is to create hierarchies of features where higher levels are formed by the features of lower levels. The introduction includes visual examples.\",\n",
      "      \"children\": []\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"2\",\n",
      "      \"title\": \"History of Deep architectures\",\n",
      "      \"content\": \"Discusses the timeline of deep learning research, from early challenges in training multi-layer networks to breakthroughs like convolutional neural networks in 1998 and major advancements in 2006 with the development of Deep Belief Networks and autoencoders.\",\n",
      "      \"children\": []\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"3\",\n",
      "      \"title\": \"Theoretical Advantages of Deep Architectures\",\n",
      "      \"content\": \"Explains the representation efficiency of deep architectures over shallow ones, conveying the computational and statistical benefits of depth in neural networks for representing complex functions.\",\n",
      "      \"children\": []\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"4\",\n",
      "      \"title\": \"Convolutional Networks\",\n",
      "      \"content\": \"Detailed explanation of convolutional networks, their structure and inspiration from the visual system's structure. It discusses LeNet 5 as a classic example with explanations of each layer and ImageNet Classification using deep convolutional networks.\",\n",
      "      \"children\": [\n",
      "        {\n",
      "          \"key\": \"4-1\",\n",
      "          \"title\": \"Deep Convolutional Networks Introduction\",\n",
      "          \"content\": \"This section introduces deep convolutional networks, emphasizing their complex structures and challenges of training, with the exception of convolutional neural networks (CNNs).\"\n",
      "        },\n",
      "        {\n",
      "          \"key\": \"4-2\",\n",
      "          \"title\": \"LeNet 5 Case Study\",\n",
      "          \"content\": \"Describes the architecture and operation of LeNet 5, providing details on its layers, their functions, and input handling.\"\n",
      "        },\n",
      "        {\n",
      "          \"key\": \"4-3\",\n",
      "          \"title\": \"ImageNet Classification with Deep Convolutional Neural Networks\",\n",
      "          \"content\": \"Outlines ImageNet's large dataset, the challenge it poses for visual recognition, and the results achieved using deep convolutional networks.\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import json,re,time\n",
    "\n",
    "def get_assistant_response(user_input, thread_id, assistant_id, file_id):\n",
    "            # 创建消息\n",
    "            message = client.beta.threads.messages.create(\n",
    "                thread_id=thread_id,\n",
    "                role=\"user\",\n",
    "                content=user_input,\n",
    "                file_ids=[file_id]\n",
    "            )\n",
    "\n",
    "            # 4. run thread\n",
    "            # Thread 默认不会运行，需要创建一个 Run 任务来执行 Thread。\n",
    "            run = client.beta.threads.runs.create(\n",
    "                thread_id=thread_id,\n",
    "                assistant_id=assistant_id,\n",
    "            )\n",
    "\n",
    "            # 等待运行任务完成\n",
    "            # Thread 是异步执行的，需要轮询检查是否执行完成。\n",
    "            # Thread 执行时会上锁，在执行完成前不可以再添加 message 或者提交新的 Run 任务。\n",
    "            while True:\n",
    "                run = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run.id)\n",
    "                if run.status not in [\"queued\", \"in_progress\"]:\n",
    "                    break\n",
    "                time.sleep(1)\n",
    "\n",
    "            # 获取 AI 输出结果\n",
    "            messages = client.beta.threads.messages.list(thread_id=thread_id)\n",
    "            print(messages.data[0])\n",
    "            # 从消息中取出 AI 输出的 JSON 字符串\n",
    "            ai_output = messages.data[0].content[0].text.value\n",
    "\n",
    "            return ai_output\n",
    "\n",
    "\n",
    "OPENAI_API_KEY=\"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\"\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "file_path='../uploads/DeepArchitectures.pdf'\n",
    "with open(file_path, \"rb\") as file:  \n",
    "    content = file.read()\n",
    "filename = file_path.split(\"\\\\\")[-1]\n",
    "content_type = 'application/pdf'\n",
    "file_response = client.files.create(file=(filename, content, content_type),purpose='assistants')\n",
    "file_id = file_response.id  \n",
    "\n",
    "sample={\n",
    "            \"summary\": \"The material begins with an introduction to the basic concepts of convex sets, convex functions, convex optimization problems, and Lagrangian dyadic problems. It then explores different types of convex optimization problems, including linear programming, quadratic programming, QCQP, and SDP, and provides examples of practical applications of these problems to machine learning. References are given at the end of the document.\",\n",
    "            \"file_structure\": [\n",
    "                {\n",
    "                    \"key\": \"1\",\n",
    "                    \"title\": \"Convex Sets\",\n",
    "                    \"content\": \"A convex set is a set in which the points on a line segment between any two points are still in the set. Or, given any two points in a set, the line segment connecting those two points is also completely contained in that set.\",\n",
    "                    \"children\": [\n",
    "                        {\"key\": \"1-1\", \"title\": \"Definition of Convex Set\", \"content\": \"A convex set is a set in which the points on a line segment between any two points remain in that set. Or, given any two points in a set, the line segment connecting those two points is also completely contained in that set.\"} ,\n",
    "                        {\"key\": \"1-2\", \"title\": \"Examples of Convex Sets\", \"content\": \"For example, the unit ball is a convex set because the line segment connecting any two points in the unit ball is also completely contained within the unit ball.\"} ,\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"key\": \"2\",\n",
    "                    \"title\": \"Convex Functions\",\n",
    "                    \"content\": \"A convex function is a function in which the line connecting any two points in the domain of definition lies above the image of the function. Or, given any two points in the domain of definition and any point on the line connecting these two points, the function value at this point is not greater than the function value at the corresponding point on the line connecting the two points.\" ,\n",
    "                    \"children\": [\n",
    "                        {\"key\": \"2-1\", \"title\": \"First-order conditions for convexity\", \"content\": \"A function f(x) is convex in the domain of definition if and only if for any two points x1 and x2 in the domain of definition, there is f(x1) <= f(x2) + f'(x2)(x1 - x2), where f'(x) denotes the derivative of f(x).\"} ,\n",
    "                        {\"key\": \"2-2\", \"title\": \"Second-order conditions for convexity\", \"content\": \"A function f(x) is convex in the domain of definition if and only if its second-order derivative f''(x) is always greater than or equal to zero in the domain of definition.\"} ,\n",
    "                        {\"key\": \"2-3\", \"title\": \"Jensen's Inequality\", \"content\": \"For a convex function f and any random variable X and any convex function φ of X, Jensen's inequality states that the expectation of φ is greater than or equal to the expectation of the parameters of φ, i.e., E[φ(X)] >= φ(E[X]).\"} ,\n",
    "                        {\"key\": \"2-4\", \"title\": \"Sublevel sets\", \"content\": \"Sublevel sets of convex functions are also convex functions. Specifically, given a convex function f and a convex set S in its domain of definition, the restriction of the function to S is still a convex function.\"} ,\n",
    "                        {\"key\": \"2-5\", \"title\": \"Applications of Convex Functions\", \"content\": \"Convex functions have a wide range of applications in machine learning, for example, the loss function in a Support Vector Machine (SVM) is a convex function, which guarantees the existence and uniqueness of the globally optimal solution to the SVM problem.\"} ,\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"key\": \"3\",\n",
    "                    \"title\": \"Convex Optimization Problems\",\n",
    "                    \"content\": \"Convex optimization problems are optimization problems in which both the objective function and constraints are convex functions. These problems have good properties and can be solved efficiently using convex optimization theory and algorithms.\" ,\n",
    "                    \"children\": [\n",
    "                        {\"key\": \"3-1\", \"title\": \"Definition of Convex Optimization\", \"content\": \"Convex optimization problems are optimization problems in which both the objective function and constraints are convex functions. That is, the objective function is convex and the constraints are convex.\"} ,\n",
    "                        {\"key\": \"3-2\", \"title\": \"Global Optimization of Convex Problems\", \"content\": \"An important property of convex optimization problems is that the globally optimal solution exists and is unique. This gives the convex optimization problem a good solution property.\"} ,\n",
    "                        {\"key\": \"3-3\", \"title\": \"Examples of Convex Optimization Problems\", \"content\": \"Many common optimization problems in machine learning, such as quadratic programming problems for support vector machines and maximum likelihood estimation problems for logistic regression, can be reduced to convex optimization problems.\"} ,\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "sample_str = \"```json\\n\" + json.dumps(sample) + \"\\n```\"\n",
    "        # prmopts\n",
    "requirements = [\n",
    "            \"Describe the summary and structure of the entire document with following requirements:\",\n",
    "            \"1.'summary' is a summary of the document\",\n",
    "            \"2.'file_structure' is a tree that describes the structure of the file, depth = 2, and each node represents a chapter or section\",\n",
    "            \"3.'key' is the index of the node, only numbers and '-' are allowed\",\n",
    "            \"4.'title' is the title of the node\",\n",
    "            \"5.'content' is a description of the node in 2-3 sentences.\",\n",
    "            \"Only return JSON code without any other content\",\n",
    "            \"The JSON format refers to the example below:\",\n",
    "            sample_str\n",
    "        ]\n",
    "user_input = \"\\n\".join(requirements)\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "            name=\"File Analysis Assistant\",\n",
    "            instructions=\"You are a personal file analyzer. When giving you a file and some questions, retrieve and analyze the content of this file as you can and answer the questions as required. If you cannot parse the required Json output, you can give an empty structure that contains only keys.\",\n",
    "            tools=[{\"type\": \"retrieval\"}],\n",
    "            model=\"gpt-4-1106-preview\",\n",
    "            file_ids=[file_id]\n",
    "        )\n",
    "\n",
    "thread = client.beta.threads.create()\n",
    "thread_id_file=thread.id\n",
    "\n",
    "response=get_assistant_response(user_input, thread_id_file, assistant.id, file_id)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ThreadMessage(id='msg_9psed3cUOoERcJ6HI5VmtbZr', assistant_id='asst_MoNUOM6DISyb69fwlBSbOghf', content=[MessageContentText(text=Text(annotations=[], value='```json\\n[\\n  \"Deep architectures\",\\n  \"Convolutional networks\",\\n  \"Deep Belief networks\",\\n  \"Neural Computation\",\\n  \"Autoencoders\",\\n  \"Greedy Layer-Wise Training of Deep Networks\",\\n  \"Advances in Neural Information Processing Systems\",\\n  \"Representation of complicated functions by deep architectures\",\\n  \"Depth k architecture\",\\n  \"Computational efficiency in layers\",\\n  \"Statistical generalization\",\\n  \"Convolutional neural networks (CNN)\",\\n  \"LeNet-5\",\\n  \"Gradient-Based Learning Applied to Document Recognition\"\\n]\\n```'), type='text')], created_at=1709445523, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_mnyLVInYZ1fGovJmwzt1MUmb', thread_id='thread_Bsflj5o0hGTQr2xLdTcc3CaD')\n",
      "```json\n",
      "[\n",
      "  \"Deep architectures\",\n",
      "  \"Convolutional networks\",\n",
      "  \"Deep Belief networks\",\n",
      "  \"Neural Computation\",\n",
      "  \"Autoencoders\",\n",
      "  \"Greedy Layer-Wise Training of Deep Networks\",\n",
      "  \"Advances in Neural Information Processing Systems\",\n",
      "  \"Representation of complicated functions by deep architectures\",\n",
      "  \"Depth k architecture\",\n",
      "  \"Computational efficiency in layers\",\n",
      "  \"Statistical generalization\",\n",
      "  \"Convolutional neural networks (CNN)\",\n",
      "  \"LeNet-5\",\n",
      "  \"Gradient-Based Learning Applied to Document Recognition\"\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "sample_list=['Convex Sets',\"Jensen's Inequality\",'Convex Optimization','Linear Programming','Quadratic Programming','QCQP','SDP','Lagrangian dyadic problems']\n",
    "user_input_list='Give all the AI or deep learning related knowledge points contained in the file to avoid duplication.Only return Json code without any other content. The Json format refers to the example below:```json\\n'+ json.dumps(sample_list) + '\\n```'\n",
    "\n",
    "response_list=get_assistant_response(user_input_list, thread.id, assistant.id, file_id)\n",
    "print(response_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正则表达式获取```json```内的内容\n",
    "def extract_json_from_string(input_string):\n",
    "            # 使用正则表达式匹配JSON部分\n",
    "    json_pattern = r'```json\\n(.*?)```'\n",
    "    match = re.search(json_pattern, input_string, re.DOTALL)\n",
    "\n",
    "    if match:\n",
    "        json_str = match.group(1).strip()\n",
    "        # 转换为JSON对象\n",
    "        json_data = json.loads(json_str)\n",
    "        return json_data\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "knowledge_list=extract_json_from_string(response_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json,re,time\n",
    "\n",
    "file_path='../history/3_relations.json'\n",
    "with open(file_path, \"rb\") as file:  \n",
    "    content =file.read().decode('utf-8')\n",
    "\n",
    "sample={\n",
    "    \"nodes\": [\n",
    "      {\n",
    "        \"id\": \"Finite Horizon Markov Decision Process (MDP)\",\n",
    "        \"label\": \"Finite Horizon Markov Decision Process (MDP)\",\n",
    "        \"level\": 2,\n",
    "        \"size\": 5,\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"Linear Quadratic Regulator (LQR)\",\n",
    "        \"label\": \"Linear Quadratic Regulator (LQR)\",\n",
    "        \"level\": 6,\n",
    "        \"size\": 3,\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"Differential Dynamic Programming (DDP)\",\n",
    "        \"label\": \"Differential Dynamic Programming (DDP)\",\n",
    "        \"level\": 4,\n",
    "        \"size\": 2,\n",
    "      }\n",
    "],\n",
    "    \"links\": [\n",
    "      {\n",
    "        \"source\": \"Optimal Control Theory\",\n",
    "        \"target\": \"Finite Horizon Markov Decision Process (MDP)\",\n",
    "        \"relation\": \"includes\"\n",
    "      },\n",
    "      {\n",
    "        \"source\": \"Finite Horizon Markov Decision Process (MDP)\",\n",
    "        \"target\": \"Markov Chain\",\n",
    "        \"relation\": \"extends\"\n",
    "      },\n",
    "      {\n",
    "        \"source\": \"Linear Quadratic Regulator (LQR)\",\n",
    "        \"target\": \"State Space Model\",\n",
    "        \"relation\": \"uses\"\n",
    "      }\n",
    "]\n",
    "}\n",
    "sample_str = \"```json\\n\" + json.dumps(sample) + \"\\n```\"\n",
    "prompt='''\n",
    "Parsing the content of this paragraph, each ternary represents [subject, relationship, object], \n",
    "the following data conversion: 1.subject and object are both elements in nodes, \\\"id\\\" and \\\"label\\\" are the same. \n",
    "2.\\\"level\\\" is an integer between [1,8], 1-8 corresponds to the relationship of learning level as \n",
    "{1: \\\"Concept\\\",2: \\\"Principle / Math formula\\\",3: \\\"Application\\\",4: \\\"Implementation\\\",5: \\\" Significance / Influence\\\",\n",
    "6: \\\"Related Knowledge\\\",7: \\\"Contrast Knowledge\\\",8: \\\"Extended Knowledge\\\"}, \n",
    "please make a recommendation to a beginner based on the level of knowledge a beginner need to master this knowledge; \n",
    "3. \\\"size\\\" is an integer between [1,5], which indicates the importance of this knowledge, 1 means common, 5 means important, need to be differentiated, \n",
    "please make a recommendation to a beginner; \n",
    "4. each ternary as links in the elements, \\\"source\\\" for the subject, \\\"target\\\" is the object, \\\"relationship\\\" is the relationship. \n",
    "Only return json data, the format is as follows:\n",
    "'''\n",
    "user_input=content+prompt+sample_str\n",
    "\n",
    "OPENAI_API_KEY=\"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\"\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "            name=\"Education Specialist\",\n",
    "            instructions=\"You are an educational expert who specializes in tutoring beginners in self-study, deleting processed data while giving beginners advice on how to learn. If you cannot parse the required Json output, you can give an empty structure that contains only keys.\",\n",
    "            tools=[{\"type\": \"code_interpreter\"}],\n",
    "            model=\"gpt-4-0125-preview\"\n",
    "        )\n",
    "\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    " # 创建消息\n",
    "message = client.beta.threads.messages.create(\n",
    "                thread_id=thread.id,\n",
    "                role=\"user\",\n",
    "                content=user_input\n",
    "            )\n",
    "\n",
    "            # 4. run thread\n",
    "            # Thread 默认不会运行，需要创建一个 Run 任务来执行 Thread。\n",
    "run = client.beta.threads.runs.create(\n",
    "                thread_id=thread.id,\n",
    "                assistant_id=assistant.id,\n",
    "            )\n",
    "\n",
    "            # 等待运行任务完成\n",
    "            # Thread 是异步执行的，需要轮询检查是否执行完成。\n",
    "            # Thread 执行时会上锁，在执行完成前不可以再添加 message 或者提交新的 Run 任务。\n",
    "while True:\n",
    "  run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "  if run.status not in [\"queued\", \"in_progress\"]:\n",
    "    break\n",
    "  time.sleep(1)\n",
    "\n",
    "            # 获取 AI 输出结果\n",
    "messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "            # 从消息中取出 AI 输出的 JSON 字符串\n",
    "ai_output = messages.data[0].content[0].text.value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"nodes\": [\n",
      "    {\n",
      "      \"id\": \"Convolutional Networks\",\n",
      "      \"label\": \"Convolutional Networks\",\n",
      "      \"level\": 1,\n",
      "      \"size\": 5\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Backpropagation\",\n",
      "      \"label\": \"Backpropagation\",\n",
      "      \"level\": 2,\n",
      "      \"size\": 4\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Gradient Descent\",\n",
      "      \"label\": \"Gradient Descent\",\n",
      "      \"level\": 2,\n",
      "      \"size\": 4\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Activation Functions\",\n",
      "      \"label\": \"Activation Functions\",\n",
      "      \"level\": 2,\n",
      "      \"size\": 3\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ReLU\",\n",
      "      \"label\": \"ReLU\",\n",
      "      \"level\": 3,\n",
      "      \"size\": 3\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Kernel Size\",\n",
      "      \"label\": \"Kernel Size\",\n",
      "      \"level\": 3,\n",
      "      \"size\": 3\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Filter Size\",\n",
      "      \"label\": \"Filter Size\",\n",
      "      \"level\": 3,\n",
      "      \"size\": 3\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Padding\",\n",
      "      \"label\": \"Padding\",\n",
      "      \"level\": 3,\n",
      "      \"size\": 3\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Zero Padding\",\n",
      "      \"label\": \"Zero Padding\",\n",
      "      \"level\": 4,\n",
      "      \"size\": 3\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Pooling\",\n",
      "      \"label\": \"Pooling\",\n",
      "      \"level\": 3,\n",
      "      \"size\": 3\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Max Pooling\",\n",
      "      \"label\": \"Max Pooling\",\n",
      "      \"level\": 4,\n",
      "      \"size\": 3\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Average Pooling\",\n",
      "      \"label\": \"Average Pooling\",\n",
      "      \"level\": 4,\n",
      "      \"size\": 3\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Deep Belief Networks\",\n",
      "      \"label\": \"Deep Belief Networks\",\n",
      "      \"level\": 1,\n",
      "      \"size\": 5\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Restricted Boltzmann Machine (RBM)\",\n",
      "      \"label\": \"Restricted Boltzmann Machine (RBM)\",\n",
      "      \"level\": 2,\n",
      "      \"size\": 4\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Uniform Distribution\",\n",
      "      \"label\": \"Uniform Distribution\",\n",
      "      \"level\": 3,\n",
      "      \"size\": 2\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Vectors\",\n",
      "      \"label\": \"Vectors\",\n",
      "      \"level\": 3,\n",
      "      \"size\": 2\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Binary Outputs\",\n",
      "      \"label\": \"Binary Outputs\",\n",
      "      \"level\": 3,\n",
      "      \"size\": 3\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Non-negative Weights\",\n",
      "      \"label\": \"Non-negative Weights\",\n",
      "      \"level\": 3,\n",
      "      \"size\": 3\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Hidden Units\",\n",
      "      \"label\": \"Hidden Units\",\n",
      "      \"level\": 3,\n",
      "      \"size\": 3\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Training Data\",\n",
      "      \"label\": \"Training Data\",\n",
      "      \"level\": 4,\n",
      "      \"size\": 4\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Parameter Learning\",\n",
      "      \"label\": \"Parameter Learning\",\n",
      "      \"level\": 4,\n",
      "      \"size\": 4\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Variational Inference\",\n",
      "      \"label\": \"Variational Inference\",\n",
      "      \"level\": 4,\n",
      "      \"size\": 3\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Data Augmentation\",\n",
      "      \"label\": \"Data Augmentation\",\n",
      "      \"level\": 1,\n",
      "      \"size\": 4\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Image\",\n",
      "      \"label\": \"Image\",\n",
      "      \"level\": 2,\n",
      "      \"size\": 3\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Random Rotation\",\n",
      "      \"label\": \"Random Rotation\",\n",
      "      \"level\": 3,\n",
      "      \"size\": 2\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Random Horizontal Flip\",\n",
      "      \"label\": \"Random Horizontal Flip\",\n",
      "      \"level\": 3,\n",
      "      \"size\": 2\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Random Crop\",\n",
      "      \"label\": \"Random Crop\",\n",
      "      \"level\": 3,\n",
      "      \"size\": 2\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Text\",\n",
      "      \"label\": \"Text\",\n",
      "      \"level\": 2,\n",
      "      \"size\": 3\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Random Swap Word Order\",\n",
      "      \"label\": \"Random Swap Word Order\",\n",
      "      \"level\": 3,\n",
      "      \"size\": 2\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Random Insertion\",\n",
      "      \"label\": \"Random Insertion\",\n",
      "      \"level\": 3,\n",
      "      \"size\": 2\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Random Deletion\",\n",
      "      \"label\": \"Random Deletion\",\n",
      "      \"level\": 3,\n",
      "      \"size\": 2\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Video\",\n",
      "      \"label\": \"Video\",\n",
      "      \"level\": 2,\n",
      "      \"size\": 3\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Random Speed Change\",\n",
      "      \"label\": \"Random Speed Change\",\n",
      "      \"level\": 3,\n",
      "      \"size\": 2\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Random Cut\",\n",
      "      \"label\": \"Random Cut\",\n",
      "      \"level\": 3,\n",
      "      \"size\": 2\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Audio\",\n",
      "      \"label\": \"Audio\",\n",
      "      \"level\": 2,\n",
      "      \"size\": 3\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Random Pitch Shift\",\n",
      "      \"label\": \"Random Pitch Shift\",\n",
      "      \"level\": 3,\n",
      "      \"size\": 2\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Random Time Stretch\",\n",
      "      \"label\": \"Random Time Stretch\",\n",
      "      \"level\": 3,\n",
      "      \"size\": 2\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Dropout\",\n",
      "      \"label\": \"Dropout\",\n",
      "      \"level\": 1,\n",
      "      \"size\": 4\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Purpose\",\n",
      "      \"label\": \"Purpose\",\n",
      "      \"level\": 2,\n",
      "      \"size\": 3\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Reduce overfitting\",\n",
      "      \"label\": \"Reduce overfitting\",\n",
      "      \"level\": 3,\n",
      "      \"size\": 5\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Type\",\n",
      "      \"label\": \"Type\",\n",
      "      \"level\": 2,\n",
      "      \"size\": 3\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Probability\",\n",
      "      \"label\": \"Probability\",\n",
      "      \"level\": 3,\n",
      "      \"size\": 4\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Usage\",\n",
      "      \"label\": \"Usage\",\n",
      "      \"level\": 2,\n",
      "      \"size\": 3\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"In training\",\n",
      "      \"label\": \"In training\",\n",
      "      \"level\": 3,\n",
      "      \"size\": 4\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"In testing\",\n",
      "      \"label\": \"In testing\",\n",
      "      \"level\": 3,\n",
      "      \"size\": 2\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"LeNet 5\",\n",
      "      \"label\": \"LeNet 5\",\n",
      "      \"level\": 2,\n",
      "      \"size\": 4\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"First Convolutional Network\",\n",
      "      \"label\": \"First Convolutional Network\",\n",
      "      \"level\": 3,\n",
      "      \"size\": 4\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Early Stopping\",\n",
      "      \"label\": \"Early Stopping\",\n",
      "      \"level\": 3,\n",
      "      \"size\": 3\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Batch Normalization\",\n",
      "      \"label\": \"Batch Normalization\",\n",
      "      \"level\": 3,\n",
      "      \"size\": 4\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Gradient-Based Learning\",\n",
      "      \"label\": \"Gradient-Based Learning\",\n",
      "      \"level\": 1,\n",
      "      \"size\": 5\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Weight Update\",\n",
      "      \"label\": \"Weight Update\",\n",
      "      \"level\": 3,\n",
      "      \"size\": 3\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Accelerate Training\",\n",
      "      \"label\": \"Accelerate Training\",\n",
      "      \"level\": 3,\n",
      "      \"size\": 4\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Regularize Neural Network\",\n",
      "      \"label\": \"Regularize Neural Network\",\n",
      "      \"level\": 3,\n",
      "      \"size\": 4\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Adam Optimizer\",\n",
      "      \"label\": \"Adam Optimizer\",\n",
      "      \"level\": 3,\n",
      "      \"size\": 3\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Adaptive Learning Rate\",\n",
      "      \"label\": \"Adaptive Learning Rate\",\n",
      "      \"level\": 4,\n",
      "      \"size\": 4\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"RMSProp\",\n",
      "      \"label\": \"RMSProp\",\n",
      "      \"level\": 3,\n",
      "      \"size\": 3\n",
      "    }\n",
      "  ],\n",
      "  \"links\": [\n",
      "    {\n",
      "      \"source\": \"Convolutional Networks\",\n",
      "      \"target\": \"Backpropagation\",\n",
      "      \"relation\": \"Concept\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Convolutional Networks\",\n",
      "      \"target\": \"Activation Functions\",\n",
      "      \"relation\": \"Concept\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Convolutional Networks\",\n",
      "      \"target\": \"Kernel Size\",\n",
      "      \"relation\": \"Application\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Convolutional Networks\",\n",
      "      \"target\": \"Padding\",\n",
      "      \"relation\": \"Application\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Convolutional Networks\",\n",
      "      \"target\": \"Pooling\",\n",
      "      \"relation\": \"Application\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Convolutional Networks\",\n",
      "      \"target\": \"LeNet 5\",\n",
      "      \"relation\": \"Related Knowledge\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Backpropagation\",\n",
      "      \"target\": \"Gradient Descent\",\n",
      "      \"relation\": \"Principle / Math formula\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Activation Functions\",\n",
      "      \"target\": \"ReLU\",\n",
      "      \"relation\": \"Implementation\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Kernel Size\",\n",
      "      \"target\": \"Filter Size\",\n",
      "      \"relation\": \"Implementation\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Padding\",\n",
      "      \"target\": \"Zero Padding\",\n",
      "      \"relation\": \"Implementation\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Pooling\",\n",
      "      \"target\": \"Max Pooling\",\n",
      "      \"relation\": \"Implementation\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Pooling\",\n",
      "      \"target\": \"Average Pooling\",\n",
      "      \"relation\": \"Implementation\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Deep Belief Networks\",\n",
      "      \"target\": \"Restricted Boltzmann Machine (RBM)\",\n",
      "      \"relation\": \"Concept\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Restricted Boltzmann Machine (RBM)\",\n",
      "      \"target\": \"Uniform Distribution\",\n",
      "      \"relation\": \"Application\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Restricted Boltzmann Machine (RBM)\",\n",
      "      \"target\": \"Vectors\",\n",
      "      \"relation\": \"Application\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Restricted Boltzmann Machine (RBM)\",\n",
      "      \"target\": \"Binary Outputs\",\n",
      "      \"relation\": \"Application\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Restricted Boltzmann Machine (RBM)\",\n",
      "      \"target\": \"Non-negative Weights\",\n",
      "      \"relation\": \"Application\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Restricted Boltzmann Machine (RBM)\",\n",
      "      \"target\": \"Hidden Units\",\n",
      "      \"relation\": \"Application\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Restricted Boltzmann Machine (RBM)\",\n",
      "      \"target\": \"Training Data\",\n",
      "      \"relation\": \"Implementation\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Restricted Boltzmann Machine (RBM)\",\n",
      "      \"target\": \"Parameter Learning\",\n",
      "      \"relation\": \"Implementation\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Restricted Boltzmann Machine (RBM)\",\n",
      "      \"target\": \"Variational Inference\",\n",
      "      \"relation\": \"Implementation\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Data Augmentation\",\n",
      "      \"target\": \"Image\",\n",
      "      \"relation\": \"Concept\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Data Augmentation\",\n",
      "      \"target\": \"Text\",\n",
      "      \"relation\": \"Concept\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Data Augmentation\",\n",
      "      \"target\": \"Video\",\n",
      "      \"relation\": \"Concept\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Data Augmentation\",\n",
      "      \"target\": \"Audio\",\n",
      "      \"relation\": \"Concept\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Image\",\n",
      "      \"target\": \"Random Rotation\",\n",
      "      \"relation\": \"Application\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Image\",\n",
      "      \"target\": \"Random Horizontal Flip\",\n",
      "      \"relation\": \"Application\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Image\",\n",
      "      \"target\": \"Random Crop\",\n",
      "      \"relation\": \"Application\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Text\",\n",
      "      \"target\": \"Random Swap Word Order\",\n",
      "      \"relation\": \"Application\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Text\",\n",
      "      \"target\": \"Random Insertion\",\n",
      "      \"relation\": \"Application\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Text\",\n",
      "      \"target\": \"Random Deletion\",\n",
      "      \"relation\": \"Application\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Video\",\n",
      "      \"target\": \"Random Speed Change\",\n",
      "      \"relation\": \"Application\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Video\",\n",
      "      \"target\": \"Random Cut\",\n",
      "      \"relation\": \"Application\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Audio\",\n",
      "      \"target\": \"Random Pitch Shift\",\n",
      "      \"relation\": \"Application\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Audio\",\n",
      "      \"target\": \"Random Time Stretch\",\n",
      "      \"relation\": \"Application\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Dropout\",\n",
      "      \"target\": \"Purpose\",\n",
      "      \"relation\": \"Concept\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Dropout\",\n",
      "      \"target\": \"Type\",\n",
      "      \"relation\": \"Concept\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Dropout\",\n",
      "      \"target\": \"Usage\",\n",
      "      \"relation\": \"Principle / Math formula\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Purpose\",\n",
      "      \"target\": \"Reduce overfitting\",\n",
      "      \"relation\": \"Implementation\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Type\",\n",
      "      \"target\": \"Probability\",\n",
      "      \"relation\": \"Implementation\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Usage\",\n",
      "      \"target\": \"In training\",\n",
      "      \"relation\": \"Implementation\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Usage\",\n",
      "      \"target\": \"In testing\",\n",
      "      \"relation\": \"Implementation\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"LeNet 5\",\n",
      "      \"target\": \"First Convolutional Network\",\n",
      "      \"relation\": \"Implementation\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"LeNet 5\",\n",
      "      \"target\": \"Early Stopping\",\n",
      "      \"relation\": \"Implementation\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"LeNet 5\",\n",
      "      \"target\": \"Batch Normalization\",\n",
      "      \"relation\": \"Implementation\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Gradient-Based Learning\",\n",
      "      \"target\": \"Backpropagation\",\n",
      "      \"relation\": \"Related Knowledge\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Gradient-Based Learning\",\n",
      "      \"target\": \"Batch Normalization\",\n",
      "      \"relation\": \"Related Knowledge\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Gradient-Based Learning\",\n",
      "      \"target\": \"Dropout\",\n",
      "      \"relation\": \"Related Knowledge\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Gradient-Based Learning\",\n",
      "      \"target\": \"Adam Optimizer\",\n",
      "      \"relation\": \"Application\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Adam Optimizer\",\n",
      "      \"target\": \"Adaptive Learning Rate\",\n",
      "      \"relation\": \"Implementation\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Gradient-Based Learning\",\n",
      "      \"target\": \"RMSProp\",\n",
      "      \"relation\": \"Application\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"RMSProp\",\n",
      "      \"target\": \"Adaptive Learning Rate\",\n",
      "      \"relation\": \"Implementation\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(ai_output)\n",
    "# print(extract_json_from_string(ai_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "[\n",
      "  {\n",
      "    \"start\": 0.0,\n",
      "    \"level\": 1,\n",
      "    \"milestone\": \"Convolutional Networks\",\n",
      "    \"importance\": 5,\n",
      "    \"subknowledge\": [\n",
      "      {\n",
      "        \"level\": 2,\n",
      "        \"knowledge\": \"Backpropagation\",\n",
      "        \"importance\": 4,\n",
      "        \"content\": \"Backpropagation is a method used to calculate the gradient of the loss function with respect to the weights in the network.\"\n",
      "      },\n",
      "      {\n",
      "        \"level\": 2,\n",
      "        \"knowledge\": \"Activation Functions\",\n",
      "        \"importance\": 3,\n",
      "        \"content\": \"Activation functions introduce non-linearity into the output of a neuron.\"\n",
      "      },\n",
      "      {\n",
      "        \"level\": 3,\n",
      "        \"knowledge\": \"ReLU\",\n",
      "        \"importance\": 3,\n",
      "        \"content\": \"ReLU stands for Rectified Linear Unit and is a popular activation function that allows models to solve non-linear problems.\"\n",
      "      },\n",
      "      {\n",
      "        \"level\": 3,\n",
      "        \"knowledge\": \"Pooling\",\n",
      "        \"importance\": 3,\n",
      "        \"content\": \"Pooling reduces the dimensionality of each feature map but retains the most important information.\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"start\": 0.2,\n",
      "    \"level\": 1,\n",
      "    \"milestone\": \"Gradient-Based Learning\",\n",
      "    \"importance\": 5,\n",
      "    \"subknowledge\": [\n",
      "      {\n",
      "        \"level\": 3,\n",
      "        \"knowledge\": \"Batch Normalization\",\n",
      "        \"importance\": 4,\n",
      "        \"content\": \"Batch Normalization is a technique to provide any layer in a neural network with inputs that are zero mean/unit variance.\"\n",
      "      },\n",
      "      {\n",
      "        \"level\": 3,\n",
      "        \"knowledge\": \"Dropout\",\n",
      "        \"importance\": 4,\n",
      "        \"content\": \"Dropout is a regularization technique that prevents overfitting by dropping out units in neural networks.\"\n",
      "      },\n",
      "      {\n",
      "        \"level\": 3,\n",
      "        \"knowledge\": \"Adam Optimizer\",\n",
      "        \"importance\": 3,\n",
      "        \"content\": \"The Adam Optimizer combines the best properties of the AdaGrad and RMSProp algorithms to provide an optimization algorithm that can handle sparse gradients on noisy problems.\"\n",
      "      },\n",
      "      {\n",
      "        \"level\": 3,\n",
      "        \"knowledge\": \"RMSProp\",\n",
      "        \"importance\": 3,\n",
      "        \"content\": \"RMSProp is an optimization algorithm designed to address Adagrad's radically diminishing learning rates.\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"start\": 0.4,\n",
      "    \"level\": 1,\n",
      "    \"milestone\": \"Data Augmentation\",\n",
      "    \"importance\": 4,\n",
      "    \"subknowledge\": [\n",
      "      {\n",
      "        \"level\": 2,\n",
      "        \"knowledge\": \"Image Augmentation\",\n",
      "        \"importance\": 3,\n",
      "        \"content\": \"Techniques like rotation, flipping, and cropping are used to artificially expand the dataset.\"\n",
      "      },\n",
      "      {\n",
      "        \"level\": 2,\n",
      "        \"knowledge\": \"Text Augmentation\",\n",
      "        \"importance\": 3,\n",
      "        \"content\": \"Methods include swapping word order, inserting random words, or deleting some words to create variations.\"\n",
      "      },\n",
      "      {\n",
      "        \"level\": 2,\n",
      "        \"knowledge\": \"Audio Augmentation\",\n",
      "        \"importance\": 3,\n",
      "        \"content\": \"Involves changing pitch, speed, and adding noise to make models robust in audio recognition tasks.\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"start\": 0.6,\n",
      "    \"level\": 1,\n",
      "    \"milestone\": \"Dropout\",\n",
      "    \"importance\": 4,\n",
      "    \"subknowledge\": [\n",
      "      {\n",
      "        \"level\": 2,\n",
      "        \"knowledge\": \"Purpose of Dropout\",\n",
      "        \"importance\": 3,\n",
      "        \"content\": \"To reduce overfitting by preventing complex co-adaptations on training data.\"\n",
      "      },\n",
      "      {\n",
      "        \"level\": 2,\n",
      "        \"knowledge\": \"Probability in Dropout\",\n",
      "        \"importance\": 4,\n",
      "        \"content\": \"Determines the likelihood of neurons being dropped out during training, commonly set to 0.5.\"\n",
      "      },\n",
      "      {\n",
      "        \"level\": 2,\n",
      "        \"knowledge\": \"Usage in Training and Testing\",\n",
      "        \"importance\": 3,\n",
      "        \"content\": \"Used during training to drop units; during testing, all units are used but with their outputs weighted by the dropout probability.\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"start\": 0.8,\n",
      "    \"level\": 1,\n",
      "    \"milestone\": \"Deep Belief Networks\",\n",
      "    \"importance\": 5,\n",
      "    \"subknowledge\": [\n",
      "      {\n",
      "        \"level\": 2,\n",
      "        \"knowledge\": \"Restricted Boltzmann Machine (RBM)\",\n",
      "        \"importance\": 4,\n",
      "        \"content\": \"RBMs are stochastic neural networks that can learn a probability distribution over its set of inputs.\"\n",
      "      },\n",
      "      {\n",
      "        \"level\": 3,\n",
      "        \"knowledge\": \"Training Data and Parameter Learning\",\n",
      "        \"importance\": 4,\n",
      "        \"content\": \"Involves the use of training data for effective network parametrization and learning fine-tuned parameters.\"\n",
      "      },\n",
      "      {\n",
      "        \"level\": 3,\n",
      "        \"knowledge\": \"Variational Inference\",\n",
      "        \"importance\": 3,\n",
      "        \"content\": \"A method used to approximate complex probabilistic models in RBMs and other networks.\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import json,re,time\n",
    "\n",
    "file_path='../history/4-mindmap.json'\n",
    "with open(file_path, \"rb\") as file:  \n",
    "    content =file.read().decode('utf-8')\n",
    "\n",
    "sample=[{\n",
    "          \"start\": 0.00,\n",
    "          \"level\": 1,\n",
    "          \"milestone\": \"Ensemble Learning\",\n",
    "          \"importance\": 4,\n",
    "          \"subknowledge\": [\n",
    "              {\n",
    "                  \"level\": 2,\n",
    "                  \"knowledge\": \"Concept of Ensemble Learning\",\n",
    "                  \"importance\": 5,\n",
    "                  \"content\": \"Ensemble Learning is a machine learning technique that combines several base models in order to produce one optimal predictive model.\"\n",
    "              },\n",
    "              {\n",
    "                  \"level\": 2,\n",
    "                  \"knowledge\": \"Benefits of Ensemble Learning\",\n",
    "                  \"importance\": 2,\n",
    "                  \"content\": \"Enhances prediction accuracy and reduces the likelihood of model overfitting by leveraging the strengths of multiple models.\"\n",
    "              },\n",
    "          ]\n",
    "      },   \n",
    "      {\n",
    "          \"start\": 0.6,\n",
    "          \"level\": 5,\n",
    "          \"milestone\": \"Stacking\",\n",
    "          \"importance\": 2,\n",
    "          \"subknowledge\": [\n",
    "              {\n",
    "                  \"level\": 6,\n",
    "                  \"knowledge\": \"Introduction to Stacking\",\n",
    "                  \"importance\": 3,\n",
    "                  \"content\": \"Stacking involves training a new model to combine the predictions of several base models for improved prediction accuracy.\"\n",
    "              },\n",
    "              {\n",
    "                  \"level\": 6,\n",
    "                  \"knowledge\": \"How Stacking Works\",\n",
    "                  \"importance\": 3,\n",
    "                  \"content\": \"It works by using a meta-learner or blender that learns how to best combine the predictions of multiple base models.\"\n",
    "              },\n",
    "              {\n",
    "                  \"level\": 6,\n",
    "                  \"knowledge\": \"Implementing Stacking Models\",\n",
    "                  \"importance\": 3,\n",
    "                  \"content\": \"Implementation involves selecting base models, training them on the data, and then training a meta-model to aggregate their predictions.\"\n",
    "              },\n",
    "              {\n",
    "                  \"level\": 6,\n",
    "                  \"knowledge\": \"Use Cases and Examples of Stacking\",\n",
    "                  \"importance\": 3,\n",
    "                  \"content\": \"Stacking is widely used in various domains like finance, healthcare, and image recognition for enhancing predictive performance.\"\n",
    "              }\n",
    "          ]\n",
    "      }]\n",
    "sample_str = \"```json\\n\" + json.dumps(sample) + \"\\n```\"\n",
    "prompt = \"\"\"\n",
    "Drawing from the structured knowledge map provided, we propose a self-learning pathway tailored for beginners, comprising approximately 8-10 pivotal milestones. \n",
    "The pathway initiates at a starting point labeled \"start\" ranging from 0 to 1. \n",
    "Each learning objective is categorized under \"level\" with a scale from 1 to 8, where each level represents a progressive learning stage as follows:\n",
    "{1: \"Concept\", 2: \"Principle / Math formula\", 3: \"Principle / Math formula\", 4: \"Implementation\", 5: \"Significance / Influence\", 6: \"Related Knowledge\", 7: \"Contrast Knowledge\", 8: \"Extended Knowledge\"}. \n",
    "This categorization aids in crafting a bespoke recommendation for beginners, aligning with the essential knowledge levels they must achieve.\n",
    "Furthermore, \"milestone\" signifies critical knowledge points within the entire knowledge map, serving as significant markers in the learning journey. \n",
    "The \"importance\" of each milestone is rated on a scale from 1 to 5, with higher values indicating greater significance. \n",
    "Additionally, \"subknowledge\" outlines essential subtopics under each milestone, where \"knowledge\" refers to the specific knowledge point, and \"content\" provides a concise explanation of this point.\n",
    "Please ensure the returned data is in JSON format, with the array length exceeding 8 entries, structured as outlined:\n",
    "\"\"\"\n",
    "\n",
    "user_input=content+prompt+sample_str\n",
    "\n",
    "OPENAI_API_KEY=\"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\"\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "            name=\"Education Specialist\",\n",
    "            instructions=\"You are an educational expert who specializes in tutoring beginners in self-study, deleting processed data while giving beginners advice on how to learn. If you cannot parse the required Json output, you can give an empty structure that contains only keys.\",\n",
    "            tools=[{\"type\": \"code_interpreter\"}],\n",
    "            model=\"gpt-4-0125-preview\"\n",
    "        )\n",
    "\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    " # 创建消息\n",
    "message = client.beta.threads.messages.create(\n",
    "                thread_id=thread.id,\n",
    "                role=\"user\",\n",
    "                content=user_input\n",
    "            )\n",
    "\n",
    "            # 4. run thread\n",
    "            # Thread 默认不会运行，需要创建一个 Run 任务来执行 Thread。\n",
    "run = client.beta.threads.runs.create(\n",
    "                thread_id=thread.id,\n",
    "                assistant_id=assistant.id,\n",
    "            )\n",
    "\n",
    "            # 等待运行任务完成\n",
    "            # Thread 是异步执行的，需要轮询检查是否执行完成。\n",
    "            # Thread 执行时会上锁，在执行完成前不可以再添加 message 或者提交新的 Run 任务。\n",
    "while True:\n",
    "  run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "  if run.status not in [\"queued\", \"in_progress\"]:\n",
    "    break\n",
    "  time.sleep(1)\n",
    "\n",
    "            # 获取 AI 输出结果\n",
    "messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "            # 从消息中取出 AI 输出的 JSON 字符串\n",
    "ai_output = messages.data[0].content[0].text.value\n",
    "print(ai_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```markdown\n",
      "# Deep Learning and AI Knowledge Points\n",
      "\n",
      "### Convolutional Neural Networks (CNNs)\n",
      "\n",
      "- **Purpose of the Kernel**: \n",
      "    - Extracts features from input data using a matrix.\n",
      "    - Weights are optimized to maximize the accuracy of the network during training.\n",
      "    - Applied across multiple input channels with each output channel representing a specific feature.\n",
      "    \n",
      "    > \"This allows the network to learn and recognize patterns and features in the input data without relying on manual feature extraction.\"\n",
      "\n",
      "### Pooling Layers\n",
      "\n",
      "- **Role in Reducing Dimensionality and Increasing Robustness**:\n",
      "    - Reduces dimensionality by selecting a representative sample from each input feature, reducing computational complexity and memory consumption.\n",
      "    - Improves robustness by ignoring the influence of outliers or noise, enhancing the stability and generalization ability of the network.\n",
      "\n",
      "### Difference Between CNNs and Traditional Neural Networks\n",
      "\n",
      "- **Architecture**:\n",
      "    - CNNs have convolutional layers designed to capture local features within data, making them suitable for image and video processing.\n",
      "    - Traditional neural networks are more general-purpose and can tackle various tasks like text classification and natural language processing.\n",
      "\n",
      "- **Training Process**:\n",
      "    - CNNs use backpropagation for training which optimizes weights by comparing network output with desired output.\n",
      "    - Traditional neural networks also use backpropagation but may require more computational resources due to a larger number of parameters.\n",
      "\n",
      "### Dropout Technique\n",
      "\n",
      "- **Mechanism and Purpose**:\n",
      "    - Randomly inactivates neurons during training to prevent overfitting.\n",
      "    - Forces the model to learn more generalized features by reducing dependency on specific neurons or groups.\n",
      "\n",
      "    > \"Dropout is particularly useful in dealing with large networks or deep learning models, as it helps improve model performance.\"\n",
      "\n",
      "### Key Takeaways\n",
      "\n",
      "- **CNNs** are specialized for processing data with a grid-like topology, such as images.\n",
      "- **Pooling layers** significantly contribute to the compactness and efficiency of CNNs.\n",
      "- **Dropout** serves as a critical technique to enhance the generalization of deep learning models by mitigating the risk of overfitting.\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import json,re,time\n",
    "\n",
    "file_path='../history/7_chat-history.json'\n",
    "with open(file_path, \"rb\") as file:  \n",
    "    content =file.read().decode('utf-8')\n",
    "\n",
    "\n",
    "prompt = \"\"\"\n",
    "Please generate summarised and structured notes in markdown form based on multiple rounds of dialogue chats.\n",
    "Please ignore the content about Self-Regulated Learning(SRL) and guided dialogues. \n",
    "Only process chat content related to deep learning or AI knowledge points.\n",
    "Generate rich markdown forms, such as tables, etc., where possible, and add underlining if there are key statements that need to be highlighted.\n",
    "Only return markdown data, the format is as follows: \n",
    "```markdown \n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "user_input=prompt+content\n",
    "\n",
    "OPENAI_API_KEY=\"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\"\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "            name=\"Education Specialist\",\n",
    "            instructions=\"You are an educational expert who specializes in tutoring beginners in self-study, deleting processed data while giving beginners advice on how to learn. If you cannot parse the required Json output, you can give an empty structure that contains only keys.\",\n",
    "            tools=[{\"type\": \"code_interpreter\"}],\n",
    "            model=\"gpt-4-0125-preview\"\n",
    "        )\n",
    "\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    " # 创建消息\n",
    "message = client.beta.threads.messages.create(\n",
    "                thread_id=thread.id,\n",
    "                role=\"user\",\n",
    "                content=user_input\n",
    "            )\n",
    "\n",
    "            # 4. run thread\n",
    "            # Thread 默认不会运行，需要创建一个 Run 任务来执行 Thread。\n",
    "run = client.beta.threads.runs.create(\n",
    "                thread_id=thread.id,\n",
    "                assistant_id=assistant.id,\n",
    "            )\n",
    "\n",
    "            # 等待运行任务完成\n",
    "            # Thread 是异步执行的，需要轮询检查是否执行完成。\n",
    "            # Thread 执行时会上锁，在执行完成前不可以再添加 message 或者提交新的 Run 任务。\n",
    "while True:\n",
    "  run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "  if run.status not in [\"queued\", \"in_progress\"]:\n",
    "    break\n",
    "  time.sleep(1)\n",
    "\n",
    "            # 获取 AI 输出结果\n",
    "messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "            # 从消息中取出 AI 输出的 JSON 字符串\n",
    "ai_output = messages.data[0].content[0].text.value\n",
    "print(ai_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the chat transcripts provided, the summary of the accuracy of the answers and the overall learning performance of the beginner is as follows:\n",
      "\n",
      "**Summary of Accuracy and Learning Performance:**\n",
      "- The beginner has a mixed understanding of the concepts questioned, with correct answers to most but misunderstanding critical concepts, particularly those relating to the purpose of specific machine learning techniques.\n",
      "- The correctness of answers is as follows: 5 Correct, 1 Incorrect, 1 Misunderstood Context.\n",
      "\n",
      "**Analysis:**\n",
      "1. **ReLU Activation Function Purpose**:   \n",
      "   - **User Answered**: B. To prevent the loss function from becoming unbounded.  \n",
      "   - **Correct Answer**: The ReLU (Rectified Linear Unit) function is used to introduce non-linearity in the neural network, helping it to learn complex patterns. The purpose is not to prevent the loss function from becoming unbounded.  \n",
      "   - **Status**: Incorrect.\n",
      "\n",
      "2. **Purpose of Using Gradient Descent**:  \n",
      "   - **User Answered**: D. All of the above.  \n",
      "   - **Explanation**: Given that the specific options are not provided, if \"All of the above\" reflects choices that correctly describe gradient descent's role in minimizing the loss function to adjust weights in the network, then the answer is correct.  \n",
      "   - **Status**: Correct (Assumed based on typical context of the question).\n",
      "\n",
      "3. **Purpose of Data Augmentation**:  \n",
      "   - **User Answered**: A. To reduce the size of the dataset.  \n",
      "   - **Correct Answer**: The purpose is to artificially enlarge the dataset with label-preserving transformations to improve model generalization.  \n",
      "   - **Status**: Incorrect.\n",
      "\n",
      "4. **Purpose of Dropout**:  \n",
      "   - **User Answered**: C. Prevent overfitting.  \n",
      "   - **Correct Answer**: Dropout is indeed used to prevent overfitting by randomly ignoring neurons during the training phase, leading to a more generalizable model.  \n",
      "   - **Status**: Correct.\n",
      "\n",
      "5. **Convolutional Networks for Image Recognition**:  \n",
      "   - **User Answered**: True.  \n",
      "   - **Correct Answer**: Convolutional Networks are indeed used for tasks like image recognition effectively.  \n",
      "   - **Status**: Correct.\n",
      "\n",
      "6. **Convolutional Networks to Detect Objects in Images**:  \n",
      "   - **User Answered**: True.  \n",
      "   - **Correct Answer**: True, Convolutional Networks can be used for object detection in images, among other tasks.  \n",
      "   - **Status**: Correct.\n",
      "\n",
      "7. **Gradient-Based Learning**:  \n",
      "   - **User Answered**: True.  \n",
      "   - **Correct Answer**: True, Gradient-Based Learning utilizes the gradient of the loss function to update the model's weights and biases.  \n",
      "   - **Status**: Correct.\n",
      "\n",
      "8. **Effectiveness of Data Augmentation**:  \n",
      "   - **User Answered**: True.  \n",
      "   - **Correct Answer**: True, Data augmentation does enhance machine learning model performance by generating more diverse training data.  \n",
      "   - **Status**: Correct (Contradicts their earlier misunderstanding on data augmentation).\n",
      "\n",
      "9. **Purpose of Dropout Technique**:  \n",
      "   - **User Answered**: True.  \n",
      "   - **Correct Answer**: True, Dropout is a technique to prevent overfitting and improve the generalization of neural networks.  \n",
      "   - **Status**: Correct.\n",
      "\n",
      "**Summary of Learning Suggestions:**\n",
      "- **Reinforce Understanding of Data Augmentation**: There seems to be confusion about the purpose of data augmentation. The learner should review how data augmentation works and why it is used in machine learning.\n",
      "- **Clarify the Purpose of ReLU Activation Function**: Misunderstanding the purpose signifies a need to deepen the understanding of activation functions in neural networks.\n",
      "- **General Review of Machine Learning Techniques**: A review of fundamental machine learning techniques, focusing on their purposes and how they contribute to model performance, would be beneficial.\n",
      "\n",
      "Overall, the user is making progress but should focus on areas of misconception and review fundamental concepts to solidify their understanding.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import json,re,time\n",
    "\n",
    "file_path='../history/9_test-history.json'\n",
    "with open(file_path, \"rb\") as file:  \n",
    "    content =file.read().decode('utf-8')\n",
    "\n",
    "\n",
    "prompt = \"\"\"\n",
    "The answers are analysed on the basis of the chat transcripts provided for the user-answered self-tests.\n",
    "Please start by giving a summary of the accuracy of the answers, as well as the overall learning performance of the beginner.\n",
    "Then analyse each question for correct or incorrect answers. All require an explanation of the reason for the answer.\n",
    "At last, plaese conclude a summary of the user's learning suggestions, such as which knowledge points should be reinforced.\n",
    "Return in the form of String.\n",
    "\"\"\"\n",
    "\n",
    "user_input=prompt+content\n",
    "\n",
    "OPENAI_API_KEY=\"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\"\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "            name=\"Education Specialist\",\n",
    "            instructions=\"You are an educational expert who specializes in tutoring beginners in self-study and giving beginners advice on how to learn.\",\n",
    "            tools=[{\"type\": \"code_interpreter\"}],\n",
    "            model=\"gpt-4-0125-preview\"\n",
    "        )\n",
    "\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    " # 创建消息\n",
    "message = client.beta.threads.messages.create(\n",
    "                thread_id=thread.id,\n",
    "                role=\"user\",\n",
    "                content=user_input\n",
    "            )\n",
    "\n",
    "            # 4. run thread\n",
    "            # Thread 默认不会运行，需要创建一个 Run 任务来执行 Thread。\n",
    "run = client.beta.threads.runs.create(\n",
    "                thread_id=thread.id,\n",
    "                assistant_id=assistant.id,\n",
    "            )\n",
    "\n",
    "            # 等待运行任务完成\n",
    "            # Thread 是异步执行的，需要轮询检查是否执行完成。\n",
    "            # Thread 执行时会上锁，在执行完成前不可以再添加 message 或者提交新的 Run 任务。\n",
    "while True:\n",
    "  run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "  if run.status not in [\"queued\", \"in_progress\"]:\n",
    "    break\n",
    "  time.sleep(1)\n",
    "\n",
    "            # 获取 AI 输出结果\n",
    "messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "            # 从消息中取出 AI 输出的 JSON 字符串\n",
    "ai_output = messages.data[0].content[0].text.value\n",
    "print(ai_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "[\n",
      "    {\n",
      "        \"start\": 0.0,\n",
      "        \"level\": 8,\n",
      "        \"milestone\": \"Convolutional Networks\",\n",
      "        \"importance\": 5,\n",
      "        \"subknowledge\": [\n",
      "            {\n",
      "                \"level\": 5,\n",
      "                \"knowledge\": \"Backpropagation\",\n",
      "                \"importance\": 4,\n",
      "                \"content\": \"Backpropagation is a method used to calculate the gradient of the loss function with respect to the weights in the network.\"\n",
      "            },\n",
      "            {\n",
      "                \"level\": 5,\n",
      "                \"knowledge\": \"Activation Functions\",\n",
      "                \"importance\": 3,\n",
      "                \"content\": \"Activation functions introduce non-linearity into the output of a neuron.\"\n",
      "            },\n",
      "            {\n",
      "                \"level\": 3,\n",
      "                \"knowledge\": \"Pooling\",\n",
      "                \"importance\": 3,\n",
      "                \"content\": \"Pooling reduces the dimensionality of each feature map but retains the most important information.\"\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"start\": 0.3,\n",
      "        \"level\": 5,\n",
      "        \"milestone\": \"Gradient-Based Learning\",\n",
      "        \"importance\": 3,\n",
      "        \"subknowledge\": [\n",
      "            {\n",
      "                \"level\": 3,\n",
      "                \"knowledge\": \"Batch Normalization\",\n",
      "                \"importance\": 4,\n",
      "                \"content\": \"Batch Normalization is a technique to provide any layer in a neural network with inputs that are zero mean/unit variance.\"\n",
      "            },\n",
      "            {\n",
      "                \"level\": 3,\n",
      "                \"knowledge\": \"Dropout\",\n",
      "                \"importance\": 4,\n",
      "                \"content\": \"Dropout is a regularization technique that prevents overfitting by dropping out units in neural networks.\"\n",
      "            },\n",
      "            {\n",
      "                \"level\": 1,\n",
      "                \"knowledge\": \"Adam Optimizer\",\n",
      "                \"importance\": 3,\n",
      "                \"content\": \"The Adam Optimizer combines the best properties of the AdaGrad and RMSProp algorithms to provide an optimization algorithm that can handle sparse gradients on noisy problems.\"\n",
      "            },\n",
      "            {\n",
      "                \"level\": 1,\n",
      "                \"knowledge\": \"RMSProp\",\n",
      "                \"importance\": 3,\n",
      "                \"content\": \"RMSProp is an optimization algorithm designed to address Adagrad's radically diminishing learning rates.\"\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"start\": 0.4,\n",
      "        \"level\": 1,\n",
      "        \"milestone\": \"Data Augmentation\",\n",
      "        \"importance\": 2,\n",
      "        \"subknowledge\": [\n",
      "            {\n",
      "                \"level\": 2,\n",
      "                \"knowledge\": \"Image Augmentation\",\n",
      "                \"importance\": 3,\n",
      "                \"content\": \"Techniques like rotation, flipping, and cropping are used to artificially expand the dataset.\"\n",
      "            },\n",
      "            {\n",
      "                \"level\": 2,\n",
      "                \"knowledge\": \"Text Augmentation\",\n",
      "                \"importance\": 3,\n",
      "                \"content\": \"Methods include swapping word order, inserting random words, or deleting some words to create variations.\"\n",
      "            },\n",
      "            {\n",
      "                \"level\": 2,\n",
      "                \"knowledge\": \"Audio Augmentation\",\n",
      "                \"importance\": 3,\n",
      "                \"content\": \"Involves changing pitch, speed, and adding noise to make models robust in audio recognition tasks.\"\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"start\": 0.5,\n",
      "        \"level\": 7,\n",
      "        \"milestone\": \"Dropout\",\n",
      "        \"importance\": 5,\n",
      "        \"subknowledge\": [\n",
      "            {\n",
      "                \"level\": 1,\n",
      "                \"knowledge\": \"Purpose of Dropout\",\n",
      "                \"importance\": 3,\n",
      "                \"content\": \"To reduce overfitting by preventing complex co-adaptations on training data.\"\n",
      "            },\n",
      "            {\n",
      "                \"level\": 2,\n",
      "                \"knowledge\": \"Probability in Dropout\",\n",
      "                \"importance\": 4,\n",
      "                \"content\": \"Determines the likelihood of neurons being dropped out during training, commonly set to 0.5.\"\n",
      "            },\n",
      "            {\n",
      "                \"level\": 4,\n",
      "                \"knowledge\": \"Usage in Training and Testing\",\n",
      "                \"importance\": 3,\n",
      "                \"content\": \"Used during training to drop units; during testing, all units are used but with their outputs weighted by the dropout probability.\"\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"start\": 0.8,\n",
      "        \"level\": 3,\n",
      "        \"milestone\": \"Deep Belief Networks\",\n",
      "        \"importance\": 3,\n",
      "        \"subknowledge\": [\n",
      "            {\n",
      "                \"level\": 1,\n",
      "                \"knowledge\": \"Restricted Boltzmann Machine (RBM)\",\n",
      "                \"importance\": 4,\n",
      "                \"content\": \"RBMs are stochastic neural networks that can learn a probability distribution over its set of inputs.\"\n",
      "            },\n",
      "            {\n",
      "                \"level\": 3,\n",
      "                \"knowledge\": \"Training Data and Parameter Learning\",\n",
      "                \"importance\": 4,\n",
      "                \"content\": \"Involves the use of training data for effective network parametrization and learning fine-tuned parameters.\"\n",
      "            },\n",
      "            {\n",
      "                \"level\": 1,\n",
      "                \"knowledge\": \"Variational Inference\",\n",
      "                \"importance\": 3,\n",
      "                \"content\": \"A method used to approximate complex probabilistic models in RBMs and other networks.\"\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"start\": 0.0,\n",
      "        \"level\": 3,\n",
      "        \"milestone\": \"Rectified Linear Unit (ReLU) Purpose\",\n",
      "        \"importance\": 4,\n",
      "        \"subknowledge\": [\n",
      "            {\n",
      "                \"level\": 2,\n",
      "                \"knowledge\": \"Understanding ReLU\",\n",
      "                \"importance\": 4,\n",
      "                \"content\": \"These interactive exercises aim to clarify the purpose of ReLU (Rectified Linear Unit) and its role in introducing non-linearity in neural network models.\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import json,re,time\n",
    "\n",
    "file_path='../history/10-feedback.md'\n",
    "with open(file_path, \"rb\") as file:  \n",
    "    feedback =file.read().decode('utf-8')\n",
    "file_path='../history/6-learning_path.json'\n",
    "with open(file_path, \"rb\") as file:  \n",
    "    before =file.read().decode('utf-8')\n",
    "\n",
    "# prompt = \"\"\"\n",
    "# Firstly summarise the weak learning points in the feedback, then supplement and modify the current learning path according to the weak points.\n",
    "# Focus on Modifying and adjusting the content of milestone.\n",
    "# Drawing from the structured knowledge map provided, we propose a self-learning pathway tailored for beginners, comprising approximately 8-10 pivotal milestones. \n",
    "# The pathway initiates at a starting point labeled \"start\" ranging from 0 to 1. \n",
    "# Each learning objective is categorized under \"level\" with a scale from 1 to 8, where each level represents a progressive learning stage as follows:\n",
    "# {1: \"Concept\", 2: \"Principle / Math formula\", 3: \"Principle / Math formula\", 4: \"Implementation\", 5: \"Significance / Influence\", 6: \"Related Knowledge\", 7: \"Contrast Knowledge\", 8: \"Extended Knowledge\"}. \n",
    "# This categorization aids in crafting a bespoke recommendation for beginners, aligning with the essential knowledge levels they must achieve.\n",
    "# Furthermore, \"milestone\" signifies critical knowledge points within the entire knowledge map, serving as significant markers in the learning journey. \n",
    "# The \"importance\" of each milestone is rated on a scale from 1 to 5, with higher values indicating greater significance. \n",
    "# Additionally, \"subknowledge\" outlines essential subtopics under each milestone, where \"knowledge\" refers to the specific knowledge point, and \"content\" provides a concise explanation of this point.\n",
    "# Return the same json format as current learning path.\n",
    "# And add '```json\\n' at the top and '\\n```' at the end.\n",
    "# Feedback:\\n\n",
    "# \"\"\"\n",
    "prompt = \"\"\"\n",
    "Based on the user's mastery of the knowledge points in the feedback, \n",
    "combined with the existing learning path data, a set of learning programmes are improved for the user, returning the adjusted learning path for this learner.\n",
    "Please make sure that the json data you return to me is not the same as the learning path data I give you. Modifications should be obvious. \n",
    "Modifications should be obvious. For example, a user who has not mastered a certain knowledge point can be added as a milestone object, and a user who has mastered a certain knowledge can delete this milestone object.\n",
    "Feedback:\\n\n",
    "\"\"\"\n",
    "user_input=prompt+feedback+'\\nThe current learning path:\\n'+before+\"Return the same json format as current learning path.And add '```json\\n' at the top and '\\n```' at the end.\"\n",
    "\n",
    "OPENAI_API_KEY=\"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\"\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "            name=\"Education Specialist\",\n",
    "            instructions=\"You are an educational expert who specializes in tutoring beginners in self-study, deleting processed data while giving beginners advice on how to learn. If you cannot parse the required Json output, you can give an empty structure that contains only keys.\",\n",
    "            tools=[{\"type\": \"code_interpreter\"}],\n",
    "            model=\"gpt-4-0125-preview\"\n",
    "        )\n",
    "\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    " # 创建消息\n",
    "message = client.beta.threads.messages.create(\n",
    "                thread_id=thread.id,\n",
    "                role=\"user\",\n",
    "                content=user_input\n",
    "            )\n",
    "\n",
    "            # 4. run thread\n",
    "            # Thread 默认不会运行，需要创建一个 Run 任务来执行 Thread。\n",
    "run = client.beta.threads.runs.create(\n",
    "                thread_id=thread.id,\n",
    "                assistant_id=assistant.id,\n",
    "            )\n",
    "\n",
    "            # 等待运行任务完成\n",
    "            # Thread 是异步执行的，需要轮询检查是否执行完成。\n",
    "            # Thread 执行时会上锁，在执行完成前不可以再添加 message 或者提交新的 Run 任务。\n",
    "while True:\n",
    "  run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "  if run.status not in [\"queued\", \"in_progress\"]:\n",
    "    break\n",
    "  time.sleep(1)\n",
    "\n",
    "            # 获取 AI 输出结果\n",
    "messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "            # 从消息中取出 AI 输出的 JSON 字符串\n",
    "ai_output = messages.data[0].content[0].text.value\n",
    "print(ai_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"nodes\": [\n",
      "    {\n",
      "      \"id\": \"Natural Language Processing (NLP)\",\n",
      "      \"label\": \"Natural Language Processing (NLP)\",\n",
      "      \"level\": 1,\n",
      "      \"size\": 5\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Deep Learning\",\n",
      "      \"label\": \"Deep Learning\",\n",
      "      \"level\": 2,\n",
      "      \"size\": 5\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Word Embeddings\",\n",
      "      \"label\": \"Word Embeddings\",\n",
      "      \"level\": 3,\n",
      "      \"size\": 4\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Distributional Semantics\",\n",
      "      \"label\": \"Distributional Semantics\",\n",
      "      \"level\": 4,\n",
      "      \"size\": 3\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Co-occurrence Matrices\",\n",
      "      \"label\": \"Co-occurrence Matrices\",\n",
      "      \"level\": 5,\n",
      "      \"size\": 3\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Word2vec\",\n",
      "      \"label\": \"Word2vec\",\n",
      "      \"level\": 6,\n",
      "      \"size\": 4\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Skip-gram Model\",\n",
      "      \"label\": \"Skip-gram Model\",\n",
      "      \"level\": 7,\n",
      "      \"size\": 3\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Continuous Bag-of-Words (CBOW)\",\n",
      "      \"label\": \"Continuous Bag-of-Words (CBOW)\",\n",
      "      \"level\": 7,\n",
      "      \"size\": 3\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Negative Sampling\",\n",
      "      \"label\": \"Negative Sampling\",\n",
      "      \"level\": 6,\n",
      "      \"size\": 3\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Stochastic Gradient Descent\",\n",
      "      \"label\": \"Stochastic Gradient Descent\",\n",
      "      \"level\": 6,\n",
      "      \"size\": 4\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Backpropagation\",\n",
      "      \"label\": \"Backpropagation\",\n",
      "      \"level\": 6,\n",
      "      \"size\": 4\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Singular Value Decomposition (SVD)\",\n",
      "      \"label\": \"Singular Value Decomposition (SVD)\",\n",
      "      \"level\": 4,\n",
      "      \"size\": 3\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Transformer Models\",\n",
      "      \"label\": \"Transformer Models\",\n",
      "      \"level\": 6,\n",
      "      \"size\": 5\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"BERT\",\n",
      "      \"label\": \"BERT\",\n",
      "      \"level\": 7,\n",
      "      \"size\": 4\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Attention Mechanism\",\n",
      "      \"label\": \"Attention Mechanism\",\n",
      "      \"level\": 6,\n",
      "      \"size\": 4\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"GloVe\",\n",
      "      \"label\": \"GloVe\",\n",
      "      \"level\": 6,\n",
      "      \"size\": 3\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"FastText\",\n",
      "      \"label\": \"FastText\",\n",
      "      \"level\": 7,\n",
      "      \"size\": 3\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Neural Network Optimization\",\n",
      "      \"label\": \"Neural Network Optimization\",\n",
      "      \"level\": 5,\n",
      "      \"size\": 4\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Activation Functions\",\n",
      "      \"label\": \"Activation Functions\",\n",
      "      \"level\": 3,\n",
      "      \"size\": 3\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Recurrent Neural Networks (RNN)\",\n",
      "      \"label\": \"Recurrent Neural Networks (RNN)\",\n",
      "      \"level\": 6,\n",
      "      \"size\": 4\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"Long Short-Term Memory (LSTM)\",\n",
      "      \"label\": \"Long Short-Term Memory (LSTM)\",\n",
      "      \"level\": 7,\n",
      "      \"size\": 3\n",
      "    }\n",
      "  ],\n",
      "  \"links\": [\n",
      "    {\n",
      "      \"source\": \"Natural Language Processing (NLP)\",\n",
      "      \"target\": \"Deep Learning\",\n",
      "      \"relationship\": \"uses\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Natural Language Processing (NLP)\",\n",
      "      \"target\": \"Word Embeddings\",\n",
      "      \"relationship\": \"includes\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Word Embeddings\",\n",
      "      \"target\": \"Distributional Semantics\",\n",
      "      \"relationship\": \"based on\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Distributional Semantics\",\n",
      "      \"target\": \"Co-occurrence Matrices\",\n",
      "      \"relationship\": \"utilizes\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Word Embeddings\",\n",
      "      \"target\": \"Word2vec\",\n",
      "      \"relationship\": \"includes\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Word2vec\",\n",
      "      \"target\": \"Skip-gram Model\",\n",
      "      \"relationship\": \"includes\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Word2vec\",\n",
      "      \"target\": \"Continuous Bag-of-Words (CBOW)\",\n",
      "      \"relationship\": \"includes\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Word2vec\",\n",
      "      \"target\": \"Negative Sampling\",\n",
      "      \"relationship\": \"utilizes\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Deep Learning\",\n",
      "      \"target\": \"Stochastic Gradient Descent\",\n",
      "      \"relationship\": \"utilizes\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Deep Learning\",\n",
      "      \"target\": \"Backpropagation\",\n",
      "      \"relationship\": \"utilizes\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Distributional Semantics\",\n",
      "      \"target\": \"Singular Value Decomposition (SVD)\",\n",
      "      \"relationship\": \"utilizes\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Deep Learning\",\n",
      "      \"target\": \"Transformer Models\",\n",
      "      \"relationship\": \"includes\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Transformer Models\",\n",
      "      \"target\": \"BERT\",\n",
      "      \"relationship\": \"includes\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Transformer Models\",\n",
      "      \"target\": \"Attention Mechanism\",\n",
      "      \"relationship\": \"based on\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Word Embeddings\",\n",
      "      \"target\": \"GloVe\",\n",
      "      \"relationship\": \"includes\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Word Embeddings\",\n",
      "      \"target\": \"FastText\",\n",
      "      \"relationship\": \"includes\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Deep Learning\",\n",
      "      \"target\": \"Neural Network Optimization\",\n",
      "      \"relationship\": \"includes\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Deep Learning\",\n",
      "      \"target\": \"Activation Functions\",\n",
      "      \"relationship\": \"utilizes\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Deep Learning\",\n",
      "      \"target\": \"Recurrent Neural Networks (RNN)\",\n",
      "      \"relationship\": \"includes\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"Recurrent Neural Networks (RNN)\",\n",
      "      \"target\": \"Long Short-Term Memory (LSTM)\",\n",
      "      \"relationship\": \"includes\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import json,re,time\n",
    "\n",
    "file_path='../stanford_nlp_1/2_knowledge_list.json'\n",
    "with open(file_path, \"rb\") as file:  \n",
    "    content =file.read().decode('utf-8')\n",
    "sample={\n",
    "    \"nodes\": [\n",
    "      {\n",
    "        \"id\": \"Finite Horizon Markov Decision Process (MDP)\",\n",
    "        \"label\": \"Finite Horizon Markov Decision Process (MDP)\",\n",
    "        \"level\": 2,\n",
    "        \"size\": 5,\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"Linear Quadratic Regulator (LQR)\",\n",
    "        \"label\": \"Linear Quadratic Regulator (LQR)\",\n",
    "        \"level\": 6,\n",
    "        \"size\": 3,\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"Differential Dynamic Programming (DDP)\",\n",
    "        \"label\": \"Differential Dynamic Programming (DDP)\",\n",
    "        \"level\": 4,\n",
    "        \"size\": 2,\n",
    "      }\n",
    "],\n",
    "    \"links\": [\n",
    "      {\n",
    "        \"source\": \"Optimal Control Theory\",\n",
    "        \"target\": \"Finite Horizon Markov Decision Process (MDP)\",\n",
    "        \"relation\": \"includes\"\n",
    "      },\n",
    "      {\n",
    "        \"source\": \"Finite Horizon Markov Decision Process (MDP)\",\n",
    "        \"target\": \"Markov Chain\",\n",
    "        \"relation\": \"extends\"\n",
    "      },\n",
    "      {\n",
    "        \"source\": \"Linear Quadratic Regulator (LQR)\",\n",
    "        \"target\": \"State Space Model\",\n",
    "        \"relation\": \"uses\"\n",
    "      }\n",
    "]\n",
    "}\n",
    "sample_str = \"```json\\n\" + json.dumps(sample) + \"\\n```\"\n",
    "prompt='''\n",
    "Extend the list of provided knowledge points with other knowledge points related to this one. Construct a network structure about the knowledge point.\n",
    "the following data conversion: \n",
    "1.subject and object are both elements in nodes, \\\"id\\\" and \\\"label\\\" are the same. \n",
    "2.\\\"level\\\" is an integer between [1,8], 1-8 corresponds to the relationship of learning level as \n",
    "{1: \\\"Concept\\\",2: \\\"Principle / Math formula\\\",3: \\\"Application\\\",4: \\\"Implementation\\\",5: \\\" Significance / Influence\\\",\n",
    "6: \\\"Related Knowledge\\\",7: \\\"Contrast Knowledge\\\",8: \\\"Extended Knowledge\\\"}, \n",
    "please make a recommendation to a beginner based on the level of knowledge a beginner need to master this knowledge; \n",
    "3. \\\"size\\\" is an integer between [1,5], which indicates the importance of this knowledge, 1 means common, 5 means important, need to be differentiated, \n",
    "please make a recommendation to a beginner; \n",
    "4. each ternary as links in the elements, \\\"source\\\" for the subject, \\\"target\\\" is the object, \\\"relationship\\\" is the relationship. \n",
    "Only return json data, the format is as follows:\n",
    "'''\n",
    "user_input=content+prompt+sample_str\n",
    "\n",
    "OPENAI_API_KEY=\"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\"\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "            name=\"Education Specialist\",\n",
    "            instructions=\"You are an educational expert who specializes in tutoring beginners in self-study and giving beginners advice on how to learn. If you cannot parse the required Json output, you can give an empty structure that contains only keys.\",\n",
    "            tools=[{\"type\": \"code_interpreter\"}],\n",
    "            model=\"gpt-4-0125-preview\"\n",
    "        )\n",
    "\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    " # 创建消息\n",
    "message = client.beta.threads.messages.create(\n",
    "                thread_id=thread.id,\n",
    "                role=\"user\",\n",
    "                content=user_input\n",
    "            )\n",
    "\n",
    "            # 4. run thread\n",
    "            # Thread 默认不会运行，需要创建一个 Run 任务来执行 Thread。\n",
    "run = client.beta.threads.runs.create(\n",
    "                thread_id=thread.id,\n",
    "                assistant_id=assistant.id,\n",
    "            )\n",
    "\n",
    "            # 等待运行任务完成\n",
    "            # Thread 是异步执行的，需要轮询检查是否执行完成。\n",
    "            # Thread 执行时会上锁，在执行完成前不可以再添加 message 或者提交新的 Run 任务。\n",
    "while True:\n",
    "  run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "  if run.status not in [\"queued\", \"in_progress\"]:\n",
    "    break\n",
    "  time.sleep(1)\n",
    "\n",
    "            # 获取 AI 输出结果\n",
    "messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "            # 从消息中取出 AI 输出的 JSON 字符串\n",
    "ai_output = messages.data[0].content[0].text.value\n",
    "print(ai_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
